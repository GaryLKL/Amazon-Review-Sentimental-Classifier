{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Review Sentimental Classifiers with GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For this intern project, I successfully implemented GNNs and sequential model, such as Bi-LSTM, on Amazon reviews dataset. By following through the steps, you will get a sense of how this project started from data cleaning to model training. This tutorial only introduces the steps for training GCN or GAT models. Please change the root path and config setting as you like.\n",
    "\n",
    "> Note: The scripts for the LSTM model have not been made to production code. For someone who is interested in following up with this work, you may need to check out the jupyter notebooks under *src/models* folder directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download the example dataset\n",
    "\n",
    "I extracted some of the subsets as the benchmark datasets from [Amazon review data (2018)](https://nijianmo.github.io/amazon/index.html). Under the **\"Small\" subsets for experimentation** section, You can find a bunch of reviews splitted into categories with the link. For this tutorial, *Magazine Subscriptions* will be taken as an example. So first of all, let's download the required dataset using wget command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-17 04:19:32--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Magazine_Subscriptions_5.json.gz\n",
      "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
      "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 401655 (392K) [application/octet-stream]\n",
      "Saving to: 'dataset/raw_datasets/Magazine_Subscriptions_5.json.gz'\n",
      "\n",
      "100%[======================================>] 401,655     1.02MB/s   in 0.4s   \n",
      "\n",
      "2020-10-17 04:19:33 (1.02 MB/s) - 'dataset/raw_datasets/Magazine_Subscriptions_5.json.gz' saved [401655/401655]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P dataset/raw_datasets/ http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Magazine_Subscriptions_5.json.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded dataset is stored in a zip file. Let's unzip the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d dataset/raw_datasets/Magazine_Subscriptions_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean the reviews\n",
    "\n",
    "You can run the following script to transform the messy reviews to clean tokens. At the same time, it will produce edge indices and the unique tokens which will further represent the nodes in each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing CPU Count: 10\n",
      "=== preprocessing file 0 ===\n",
      "transform json to dataframe...\n",
      "start reading the json files...\n",
      "clean tokens and remove rows with no tokens...\n",
      "cleaning the reviews...\n",
      "100%|██████████████████████████████████████| 2375/2375 [00:05<00:00, 423.89it/s]\n",
      "remove empty tokens...\n",
      "extract unique tokens...\n",
      "getting the edge index for each graph...\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  3.29it/s]\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=\"/scratch/kll482/cathay\" python src/preprocessing/feature_engineering/feature_engineering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build pytorch geometric dataloaders\n",
    "\n",
    "After cleaning the reviews, I will build pytorch dataloaders for training, validation, and test sets before training the model. Those dataloaders are stored under \"dataset/dataloaders/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "1. Config Setting\n",
      "cuda on:  True\n",
      "2. Read all preprocessed json files\n",
      "read the datasets...\n",
      "3. Take a look at the token and unique token length distribution among all reviews\n",
      "max: 515\n",
      "min: 1\n",
      "median: 12.0\n",
      "mean: 29.536637018212623\n",
      "Quantile (25%): 3.0\n",
      "Quantile (75%): 31.0\n",
      "Quantile (90%): 78.0\n",
      "max: 317\n",
      "min: 1\n",
      "median: 12.0\n",
      "mean: 23.781872088098265\n",
      "Quantile (25%): 3.0\n",
      "Quantile (75%): 28.0\n",
      "Quantile (90%): 64.0\n",
      "5. Reclassify overall score from 1~5 to [0,1], representing negative and positive\n",
      "6. Make sure there is no NA value in the new target column\n",
      "7. Split the dataframe into train, validation, and test sets\n",
      "8. Create a vocabulary from unique tokens\n",
      "9. Conduct undersampling on the based on the target variable distribution\n",
      "Length of training set: 338\n",
      "Length of test set: 237\n",
      "10. Build Pytorch dataset for all neighbors\n",
      "11. Build and save Pytorch dataloaders\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=\"/scratch/kll482/cathay\" python src/preprocessing/build_loaders.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take a few seconds to set up the config/arguments. Please be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Config Setting\n",
      "cuda on:  True\n",
      "Which model I am training? gcn \n",
      "\n",
      "size of train loader 22\n",
      "\n",
      "=== The nodes within the same graph are connecting with only 1 neighbors. Let's start training ===\n",
      "=== Settings ===\n",
      "data_path: dataset/processed_datasets/\n",
      "data_loader_path: dataset/dataloaders/\n",
      "model_name: gcn\n",
      "use_cuda: True\n",
      "set_seed: 123\n",
      "num_features: 768\n",
      "n_classes: 1\n",
      "target: y\n",
      "neighbor: 1,2\n",
      "nodes: uniqueTokens\n",
      "tokens: reviewTokens\n",
      "embedd_method: random\n",
      "test_batch_size: 1024\n",
      "batch_size: 16\n",
      "epochs: 15\n",
      "log_every: 10\n",
      "lr: 0.001\n",
      "drop_out: 0.0\n",
      "lr_decay: 0.7\n",
      "lr_min: 1e-05\n",
      "n_bad_loss: 4.0\n",
      "result_path: result/graph/\n",
      "log_path: logs/graph/\n",
      "result: result/\n",
      "device: cuda\n",
      "num_words: 160993\n",
      "edge_index: edgeIndex1\n",
      "best_model: result/graph/checkpoint/edgeIndex1_gcn_2020_10_17_04_43.pth\n",
      "log_file: logs/graph/edgeIndex1_gcn_2020_10_17_04_43.txt\n",
      "config_saved_path: result/graph/config_saved/edgeIndex1_gcn_2020_10_17_04_43.pkl\n",
      "iteration: 0\n",
      "n_total: 0\n",
      "train_loss: 0\n",
      "init_bad_loss: 0\n",
      "stop: False\n",
      "best_val_loss: inf\n",
      "init: 2020-10-17 04:43:35.935705\n",
      "============\n",
      "\n",
      "Start record at 2020-10-17 04:43:35.936540\n",
      "=> EPOCH 1\n",
      "8it [00:08,  2.83s/it]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.48it/s]\u001b[A\n",
      "   % Time: 0:00:08.838939 | Iteration:    10 | Batch:   10/22 | Train loss: 0.6238 | Val loss: 0.6221\n",
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "19it [00:09,  1.32it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.74it/s]\u001b[A\n",
      "   % Time: 0:00:10.080401 | Iteration:    20 | Batch:   20/22 | Train loss: 0.6063 | Val loss: 0.5872\n",
      "22it [00:10,  2.01it/s]\n",
      "=> EPOCH 2\n",
      "6it [00:00, 22.74it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 15.51it/s]\u001b[A\n",
      "   % Time: 0:00:11.415590 | Iteration:    30 | Batch:    8/22 | Train loss: 0.4853 | Val loss: 0.5897\n",
      "17it [00:00, 22.73it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.89it/s]\u001b[A\n",
      "   % Time: 0:00:11.871964 | Iteration:    40 | Batch:   18/22 | Train loss: 0.4702 | Val loss: 0.5801\n",
      "22it [00:02, 10.52it/s]\n",
      "=> EPOCH 3\n",
      "3it [00:00, 25.14it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.80it/s]\u001b[A\n",
      "   % Time: 0:00:13.407714 | Iteration:    50 | Batch:    6/22 | Train loss: 0.4235 | Val loss: 0.5665\n",
      "15it [00:01, 14.04it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.81it/s]\u001b[A\n",
      "   % Time: 0:00:14.723677 | Iteration:    60 | Batch:   16/22 | Train loss: 0.4210 | Val loss: 0.5620\n",
      "22it [00:03,  6.93it/s]\n",
      "=> EPOCH 4\n",
      "3it [00:00, 24.53it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.69it/s]\u001b[A\n",
      "   % Time: 0:00:16.524083 | Iteration:    70 | Batch:    4/22 | Train loss: 0.4063 | Val loss: 0.5535\n",
      "13it [00:01,  7.38it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.87it/s]\u001b[A\n",
      "   % Time: 0:00:17.846576 | Iteration:    80 | Batch:   14/22 | Train loss: 0.3552 | Val loss: 0.5575\n",
      "22it [00:01, 11.83it/s]\n",
      "=> EPOCH 5\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.95it/s]\u001b[A\n",
      "   % Time: 0:00:18.298991 | Iteration:    90 | Batch:    2/22 | Train loss: 0.3392 | Val loss: 0.5496\n",
      "11it [00:01,  4.57it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.75it/s]\u001b[A\n",
      "   % Time: 0:00:19.750012 | Iteration:   100 | Batch:   12/22 | Train loss: 0.3383 | Val loss: 0.5428\n",
      "19it [00:02,  5.90it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.34it/s]\u001b[A\n",
      "   % Time: 0:00:21.087828 | Iteration:   110 | Batch:   22/22 | Train loss: 0.2998 | Val loss: 0.5655\n",
      "22it [00:02,  7.51it/s]\n",
      "=> EPOCH 6\n",
      "9it [00:00, 25.35it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.97it/s]\u001b[A\n",
      "   % Time: 0:00:21.544132 | Iteration:   120 | Batch:   10/22 | Train loss: 0.2826 | Val loss: 0.5707\n",
      "17it [00:00, 22.24it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.26it/s]\u001b[A\n",
      "   % Time: 0:00:22.010339 | Iteration:   130 | Batch:   20/22 | Train loss: 0.3034 | Val loss: 0.5495\n",
      "22it [00:00, 22.08it/s]\n",
      "=> EPOCH 7\n",
      "6it [00:00, 25.38it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.21it/s]\u001b[A\n",
      "   % Time: 0:00:22.460997 | Iteration:   140 | Batch:    8/22 | Train loss: 0.3061 | Val loss: 0.5485\n",
      "=> Adjust learning rate to: 0.0007\n",
      "17it [00:00, 23.57it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.19it/s]\u001b[A\n",
      "   % Time: 0:00:22.914665 | Iteration:   150 | Batch:   18/22 | Train loss: 0.2396 | Val loss: 0.5553\n",
      "22it [00:00, 22.35it/s]\n",
      "=> EPOCH 8\n",
      "3it [00:00, 23.26it/s]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.62s/it]\u001b[A\n",
      "   % Time: 0:00:25.946207 | Iteration:   160 | Batch:    6/22 | Train loss: 0.2562 | Val loss: 0.5660\n",
      "14it [00:03,  7.50it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.05it/s]\u001b[A\n",
      "   % Time: 0:00:26.531940 | Iteration:   170 | Batch:   16/22 | Train loss: 0.2336 | Val loss: 0.5617\n",
      "22it [00:03,  5.94it/s]\n",
      "=> EPOCH 9\n",
      "3it [00:00, 24.80it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.65it/s]\u001b[A\n",
      "   % Time: 0:00:27.024461 | Iteration:   180 | Batch:    4/22 | Train loss: 0.2606 | Val loss: 0.5595\n",
      "=> Adjust learning rate to: 0.00049\n",
      "13it [00:00, 20.23it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 15.95it/s]\u001b[A\n",
      "   % Time: 0:00:27.494378 | Iteration:   190 | Batch:   14/22 | Train loss: 0.2174 | Val loss: 0.5549\n",
      "22it [00:01, 12.09it/s]\n",
      "=> EPOCH 10\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.11it/s]\u001b[A\n",
      "   % Time: 0:00:28.734647 | Iteration:   200 | Batch:    2/22 | Train loss: 0.2088 | Val loss: 0.5657\n",
      "11it [00:00, 20.12it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.21it/s]\u001b[A\n",
      "   % Time: 0:00:29.190402 | Iteration:   210 | Batch:   12/22 | Train loss: 0.2107 | Val loss: 0.5663\n",
      "19it [00:00, 20.76it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.84it/s]\u001b[A\n",
      "   % Time: 0:00:29.652554 | Iteration:   220 | Batch:   22/22 | Train loss: 0.2370 | Val loss: 0.5638\n",
      "22it [00:01, 20.83it/s]\n",
      "=> EPOCH 11\n",
      "9it [00:00, 25.36it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.84it/s]\u001b[A\n",
      "   % Time: 0:00:30.108773 | Iteration:   230 | Batch:   10/22 | Train loss: 0.2139 | Val loss: 0.5591\n",
      "=> Adjust learning rate to: 0.000343\n",
      "17it [00:00, 22.73it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.90it/s]\u001b[A\n",
      "   % Time: 0:00:30.565423 | Iteration:   240 | Batch:   20/22 | Train loss: 0.2170 | Val loss: 0.5616\n",
      "22it [00:00, 22.28it/s]\n",
      "=> EPOCH 12\n",
      "6it [00:00, 24.09it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.23it/s]\u001b[A\n",
      "   % Time: 0:00:31.026045 | Iteration:   250 | Batch:    8/22 | Train loss: 0.2123 | Val loss: 0.5613\n",
      "17it [00:00, 23.29it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.17it/s]\u001b[A\n",
      "   % Time: 0:00:31.479460 | Iteration:   260 | Batch:   18/22 | Train loss: 0.2029 | Val loss: 0.5614\n",
      "22it [00:00, 22.21it/s]\n",
      "=> EPOCH 13\n",
      "3it [00:00, 25.38it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.26it/s]\u001b[A\n",
      "   % Time: 0:00:31.929036 | Iteration:   270 | Batch:    6/22 | Train loss: 0.1693 | Val loss: 0.5589\n",
      "15it [00:01, 14.00it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.78it/s]\u001b[A\n",
      "   % Time: 0:00:33.253919 | Iteration:   280 | Batch:   16/22 | Train loss: 0.2162 | Val loss: 0.5606\n",
      "22it [00:01, 11.87it/s]\n",
      "=> EPOCH 14\n",
      "3it [00:00, 25.26it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.85it/s]\u001b[A\n",
      "   % Time: 0:00:33.707266 | Iteration:   290 | Batch:    4/22 | Train loss: 0.2034 | Val loss: 0.5592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13it [00:00, 21.54it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.79it/s]\u001b[A\n",
      "   % Time: 0:00:34.174358 | Iteration:   300 | Batch:   14/22 | Train loss: 0.1824 | Val loss: 0.5574\n",
      "22it [00:02,  7.52it/s]\n",
      "=> EPOCH 15\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.47it/s]\u001b[A\n",
      "   % Time: 0:00:36.654272 | Iteration:   310 | Batch:    2/22 | Train loss: 0.1887 | Val loss: 0.5621\n",
      "11it [00:00, 14.94it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.92it/s]\u001b[A\n",
      "   % Time: 0:00:37.113123 | Iteration:   320 | Batch:   12/22 | Train loss: 0.1801 | Val loss: 0.5616\n",
      "19it [00:00, 18.47it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.24it/s]\u001b[A\n",
      "   % Time: 0:00:37.573082 | Iteration:   330 | Batch:   22/22 | Train loss: 0.2068 | Val loss: 0.5633\n",
      "22it [00:01, 19.05it/s]\n",
      "size of train loader 22\n",
      "\n",
      "=== The nodes within the same graph are connecting with only 2 neighbors. Let's start training ===\n",
      "=== Settings ===\n",
      "data_path: dataset/processed_datasets/\n",
      "data_loader_path: dataset/dataloaders/\n",
      "model_name: gcn\n",
      "use_cuda: True\n",
      "set_seed: 123\n",
      "num_features: 768\n",
      "n_classes: 1\n",
      "target: y\n",
      "neighbor: 1,2\n",
      "nodes: uniqueTokens\n",
      "tokens: reviewTokens\n",
      "embedd_method: random\n",
      "test_batch_size: 1024\n",
      "batch_size: 16\n",
      "epochs: 15\n",
      "log_every: 10\n",
      "lr: 0.001\n",
      "drop_out: 0.0\n",
      "lr_decay: 0.7\n",
      "lr_min: 1e-05\n",
      "n_bad_loss: 4.0\n",
      "result_path: result/graph/\n",
      "log_path: logs/graph/\n",
      "result: result/\n",
      "device: cuda\n",
      "num_words: 160993\n",
      "edge_index: edgeIndex2\n",
      "best_model: result/graph/checkpoint/edgeIndex2_gcn_2020_10_17_04_44.pth\n",
      "log_file: logs/graph/edgeIndex2_gcn_2020_10_17_04_44.txt\n",
      "config_saved_path: result/graph/config_saved/edgeIndex2_gcn_2020_10_17_04_44.pkl\n",
      "iteration: 0\n",
      "n_total: 0\n",
      "train_loss: 0\n",
      "init_bad_loss: 0\n",
      "stop: False\n",
      "best_val_loss: inf\n",
      "init: 2020-10-17 04:44:13.992097\n",
      "============\n",
      "\n",
      "Start record at 2020-10-17 04:44:13.992454\n",
      "=> EPOCH 1\n",
      "7it [00:00,  7.56it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.24it/s]\u001b[A\n",
      "   % Time: 0:00:00.688002 | Iteration:    10 | Batch:   10/22 | Train loss: 0.1418 | Val loss: 0.5954\n",
      "19it [00:01, 11.32it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.48it/s]\u001b[A\n",
      "   % Time: 0:00:01.830343 | Iteration:    20 | Batch:   20/22 | Train loss: 0.1906 | Val loss: 0.5452\n",
      "22it [00:02,  7.90it/s]\n",
      "=> EPOCH 2\n",
      "6it [00:00, 24.46it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.52it/s]\u001b[A\n",
      "   % Time: 0:00:03.174028 | Iteration:    30 | Batch:    8/22 | Train loss: 0.0687 | Val loss: 0.6158\n",
      "17it [00:00, 23.17it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.61it/s]\u001b[A\n",
      "   % Time: 0:00:03.633004 | Iteration:    40 | Batch:   18/22 | Train loss: 0.0810 | Val loss: 0.5762\n",
      "22it [00:01, 20.60it/s]\n",
      "=> EPOCH 3\n",
      "3it [00:00, 25.18it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.64it/s]\u001b[A\n",
      "   % Time: 0:00:04.157842 | Iteration:    50 | Batch:    6/22 | Train loss: 0.0753 | Val loss: 0.6130\n",
      "15it [00:00, 23.94it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.56it/s]\u001b[A\n",
      "   % Time: 0:00:04.615923 | Iteration:    60 | Batch:   16/22 | Train loss: 0.0624 | Val loss: 0.6210\n",
      "=> Adjust learning rate to: 0.0007\n",
      "22it [00:00, 22.16it/s]\n",
      "=> EPOCH 4\n",
      "3it [00:00, 25.23it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.62it/s]\u001b[A\n",
      "   % Time: 0:00:05.071935 | Iteration:    70 | Batch:    4/22 | Train loss: 0.0597 | Val loss: 0.6139\n",
      "13it [00:01,  7.29it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.15it/s]\u001b[A\n",
      "   % Time: 0:00:06.421858 | Iteration:    80 | Batch:   14/22 | Train loss: 0.0504 | Val loss: 0.6310\n",
      "22it [00:01, 11.68it/s]\n",
      "=> EPOCH 5\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.63it/s]\u001b[A\n",
      "   % Time: 0:00:06.877681 | Iteration:    90 | Batch:    2/22 | Train loss: 0.0337 | Val loss: 0.6402\n",
      "10it [00:00, 16.06it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.46it/s]\u001b[A\n",
      "   % Time: 0:00:07.514788 | Iteration:   100 | Batch:   12/22 | Train loss: 0.0477 | Val loss: 0.6337\n",
      "21it [00:01, 20.27it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.61it/s]\u001b[A\n",
      "   % Time: 0:00:07.974796 | Iteration:   110 | Batch:   22/22 | Train loss: 0.0351 | Val loss: 0.6619\n",
      "=> Adjust learning rate to: 0.00049\n",
      "22it [00:01, 17.76it/s]\n",
      "=> EPOCH 6\n",
      "8it [00:00, 21.90it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.04it/s]\u001b[A\n",
      "   % Time: 0:00:08.486585 | Iteration:   120 | Batch:   10/22 | Train loss: 0.0319 | Val loss: 0.6611\n",
      "19it [00:01, 10.99it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.66it/s]\u001b[A\n",
      "   % Time: 0:00:09.841089 | Iteration:   130 | Batch:   20/22 | Train loss: 0.0444 | Val loss: 0.6651\n",
      "22it [00:01, 11.33it/s]\n",
      "=> EPOCH 7\n",
      "6it [00:00, 25.27it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.92it/s]\u001b[A\n",
      "   % Time: 0:00:10.295448 | Iteration:   140 | Batch:    8/22 | Train loss: 0.0454 | Val loss: 0.6705\n",
      "17it [00:00, 23.44it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.91it/s]\u001b[A\n",
      "   % Time: 0:00:10.751757 | Iteration:   150 | Batch:   18/22 | Train loss: 0.0255 | Val loss: 0.6720\n",
      "22it [00:00, 22.28it/s]\n",
      "=> EPOCH 8\n",
      "3it [00:00, 25.27it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.88it/s]\u001b[A\n",
      "   % Time: 0:00:11.204338 | Iteration:   160 | Batch:    6/22 | Train loss: 0.0430 | Val loss: 0.6821\n",
      "=> Adjust learning rate to: 0.000343\n",
      "15it [00:00, 24.01it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.90it/s]\u001b[A\n",
      "   % Time: 0:00:11.660680 | Iteration:   170 | Batch:   16/22 | Train loss: 0.0220 | Val loss: 0.6840\n",
      "22it [00:00, 22.03it/s]\n",
      "=> EPOCH 9\n",
      "3it [00:00, 24.94it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.56it/s]\u001b[A\n",
      "   % Time: 0:00:12.128305 | Iteration:   180 | Batch:    4/22 | Train loss: 0.0412 | Val loss: 0.6865\n",
      "13it [00:00, 21.30it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.55it/s]\u001b[A\n",
      "   % Time: 0:00:12.597382 | Iteration:   190 | Batch:   14/22 | Train loss: 0.0246 | Val loss: 0.6817\n",
      "22it [00:01, 11.29it/s]\n",
      "=> EPOCH 10\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.49it/s]\u001b[A\n",
      "   % Time: 0:00:13.997713 | Iteration:   200 | Batch:    2/22 | Train loss: 0.0246 | Val loss: 0.6915\n",
      "11it [00:00, 19.38it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.86it/s]\u001b[A\n",
      "   % Time: 0:00:14.471305 | Iteration:   210 | Batch:   12/22 | Train loss: 0.0236 | Val loss: 0.6940\n",
      "19it [00:00, 20.68it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.86it/s]\u001b[A\n",
      "   % Time: 0:00:14.925999 | Iteration:   220 | Batch:   22/22 | Train loss: 0.0371 | Val loss: 0.6940\n",
      "22it [00:01, 20.56it/s]\n",
      "=> EPOCH 11\n",
      "9it [00:00, 25.30it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.88it/s]\u001b[A\n",
      "   % Time: 0:00:15.383012 | Iteration:   230 | Batch:   10/22 | Train loss: 0.0236 | Val loss: 0.6924\n",
      "=> Adjust learning rate to: 0.00024009999999999998\n",
      "17it [00:00, 22.72it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.90it/s]\u001b[A\n",
      "   % Time: 0:00:15.839553 | Iteration:   240 | Batch:   20/22 | Train loss: 0.0354 | Val loss: 0.6956\n",
      "22it [00:00, 22.27it/s]\n",
      "=> EPOCH 12\n",
      "6it [00:00, 25.26it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 13.06it/s]\u001b[A\n",
      "   % Time: 0:00:16.316336 | Iteration:   250 | Batch:    8/22 | Train loss: 0.0328 | Val loss: 0.6988\n",
      "17it [00:00, 22.32it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.54it/s]\u001b[A\n",
      "   % Time: 0:00:16.791621 | Iteration:   260 | Batch:   18/22 | Train loss: 0.0235 | Val loss: 0.6976\n",
      "22it [00:01, 18.70it/s]\n",
      "=> EPOCH 13\n",
      "4it [00:00, 12.09it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.13it/s]\u001b[A\n",
      "   % Time: 0:00:17.467422 | Iteration:   270 | Batch:    6/22 | Train loss: 0.0191 | Val loss: 0.6944\n",
      "=> Adjust learning rate to: 0.00016806999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15it [00:00, 18.55it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.55it/s]\u001b[A\n",
      "   % Time: 0:00:17.936141 | Iteration:   280 | Batch:   16/22 | Train loss: 0.0237 | Val loss: 0.6978\n",
      "22it [00:01, 20.55it/s]\n",
      "=> EPOCH 14\n",
      "3it [00:00, 25.16it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.29it/s]\u001b[A\n",
      "   % Time: 0:00:18.393812 | Iteration:   290 | Batch:    4/22 | Train loss: 0.0334 | Val loss: 0.6987\n",
      "13it [00:00, 21.49it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.54it/s]\u001b[A\n",
      "   % Time: 0:00:18.856289 | Iteration:   300 | Batch:   14/22 | Train loss: 0.0207 | Val loss: 0.6979\n",
      "22it [00:00, 22.04it/s]\n",
      "=> EPOCH 15\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.45it/s]\u001b[A\n",
      "   % Time: 0:00:19.312228 | Iteration:   310 | Batch:    2/22 | Train loss: 0.0305 | Val loss: 0.7024\n",
      "=> Adjust learning rate to: 0.00011764899999999998\n",
      "11it [00:00, 19.53it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 14.96it/s]\u001b[A\n",
      "   % Time: 0:00:19.788601 | Iteration:   320 | Batch:   12/22 | Train loss: 0.0224 | Val loss: 0.7023\n",
      "19it [00:01,  9.22it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 16.47it/s]\u001b[A\n",
      "   % Time: 0:00:21.055470 | Iteration:   330 | Batch:   22/22 | Train loss: 0.0322 | Val loss: 0.7037\n",
      "22it [00:01, 11.67it/s]\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=\"/scratch/kll482/cathay\" python training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Testing the model and compute the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Prepare for initial settings\n",
      "2. Start testing\n",
      "start testing...\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.14s/it]\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "    0    1\n",
      "0  11   12\n",
      "1  80  134\n",
      "\n",
      "Finished testing\n",
      "3. Write the classification report...\n",
      "\n",
      "=== Classification Report ===\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.12      0.48      0.19        23\n",
      "         1.0       0.92      0.63      0.74       214\n",
      "\n",
      "    accuracy                           0.61       237\n",
      "   macro avg       0.52      0.55      0.47       237\n",
      "weighted avg       0.84      0.61      0.69       237\n",
      "\n",
      "\n",
      "4. Plot the learning curve and save it...\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=\"/scratch/kll482/cathay\" python testing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
