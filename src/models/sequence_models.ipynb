{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:23.407418Z",
     "start_time": "2020-08-05T07:13:23.398377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /scratch/kll482/cathay\n",
      "Config Sections: ['text_cleaning', 'feature_engineering', 'graph_models']\n"
     ]
    }
   ],
   "source": [
    "''' root '''\n",
    "import os\n",
    "os.chdir(\"/scratch/kll482/cathay\")\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/scratch/kll482/cathay/\")\n",
    "\n",
    "''' config '''\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"config/config.ini\")\n",
    "print(\"Config Sections:\", config.sections())\n",
    "args = config[\"graph_models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:15:33.614186Z",
     "start_time": "2020-08-05T07:15:33.609071Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' packages '''\n",
    "# import torch, torchvision\n",
    "# import pandas as pd, numpy as np\n",
    "# import argparse\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# # from torch_geometric.data.InMemoryDataset import collate\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' packages '''\n",
    "# 1. models\n",
    "import torch, torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 2. others\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import pandas as pd, numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter(\"logs/graph/\")\n",
    "\n",
    "# 3. custom\n",
    "from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "from src.utils.vocabulary import Vocabulary\n",
    "from src.utils.pipeline import Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initial Variables & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:28.592867Z",
     "start_time": "2020-08-05T07:13:28.589113Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Hyperparameters '''\n",
    "parser = {\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 5, # random seed\n",
    "    \"epochs\": 5,\n",
    "    \"cuda\": True, # use cuda or not\n",
    "    \"log_every\": 100,\n",
    "    \"lr\": 0.01,  # initial learning rate\n",
    "    \"lr_decay\": 0.7,  # decay lr when not observing improvement in val_loss\n",
    "    \"lr_min\": 1e-5,  # stop when lr is too low\n",
    "    \"n_bad_loss\": 4,  # number of bad val_loss before decaying\n",
    "    \"clip\": 2.3,\n",
    "    \"result_path\": \"result/sequence/\",  # path to save models\n",
    "    \"log_path\": \"logs/sequence/\",\n",
    "}\n",
    "config = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' General '''\n",
    "config.USE_CUDA = 1 # bool(int(args[\"use_cuda\"]))\n",
    "config.SEED = int(args[\"set_seed\"])\n",
    "config.MODELING_FEATURE_PATH = args[\"modeling_feature_path\"]\n",
    "config.DATA_PATH = args[\"data_path\"]\n",
    "config.NUM_FEATURES = 768\n",
    "config.N_CLASSES = 1\n",
    "config.TARGET = \"overall\"\n",
    "config.TOKENS = \"reviewTokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. CUDA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.284510Z",
     "start_time": "2020-08-05T07:13:29.276557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda on:  True\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config.USE_CUDA = config.USE_CUDA and torch.cuda.is_available()\n",
    "print(\"cuda on: \", config.USE_CUDA)\n",
    "if config.USE_CUDA:\n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    torch.manual_seed(config.SEED)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if config.USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.480321Z",
     "start_time": "2020-08-05T07:13:29.476385Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=config.SEED):\n",
    "    #random.seed(seed)\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:14:27.559723Z",
     "start_time": "2020-08-05T07:13:30.485201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"read the datasets...\")\n",
    "files = []\n",
    "# file_path = [file for file in os.listdir(config.DATA_PATH) if file.endswith(\".json\")]\n",
    "# file_path = ['Video_Games_5.json', 'Musical_Instruments_5.json']\n",
    "file_path = ['straight_Musical_Instruments_5.json']\n",
    "config.dataset_used = \"\\t\".join(file_path)\n",
    "\n",
    "for file in file_path:    \n",
    "    files.append(pd.read_json(os.path.join(config.DATA_PATH, file)))\n",
    "    \n",
    "df = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230981, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTokens</th>\n",
       "      <th>uniqueTokens</th>\n",
       "      <th>edgeIndex1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It's good for beginners</td>\n",
       "      <td>[good, beginner]</td>\n",
       "      <td>[good, beginner]</td>\n",
       "      <td>[[0, 1], [1, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I recommend this starter Ukulele kit.  I has e...</td>\n",
       "      <td>[recommend, starter, ukulele, kit, everything,...</td>\n",
       "      <td>[learn, kit, starter, recommend, ukulele, ever...</td>\n",
       "      <td>[[3, 2, 2, 4, 4, 1, 1, 5, 5, 6, 6, 0, 0, 4], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>G'daughter received this for Christmas present...</td>\n",
       "      <td>[g, daughter, receive, christmas, present, las...</td>\n",
       "      <td>[receive, year, play, daughter, g, present, la...</td>\n",
       "      <td>[[4, 3, 3, 0, 0, 7, 7, 5, 5, 6, 6, 1, 1, 2, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0        5                            It's good for beginners   \n",
       "1        5  I recommend this starter Ukulele kit.  I has e...   \n",
       "2        5  G'daughter received this for Christmas present...   \n",
       "\n",
       "                                        reviewTokens  \\\n",
       "0                                   [good, beginner]   \n",
       "1  [recommend, starter, ukulele, kit, everything,...   \n",
       "2  [g, daughter, receive, christmas, present, las...   \n",
       "\n",
       "                                        uniqueTokens  \\\n",
       "0                                   [good, beginner]   \n",
       "1  [learn, kit, starter, recommend, ukulele, ever...   \n",
       "2  [receive, year, play, daughter, g, present, la...   \n",
       "\n",
       "                                          edgeIndex1  \n",
       "0                                   [[0, 1], [1, 0]]  \n",
       "1  [[3, 2, 2, 4, 4, 1, 1, 5, 5, 6, 6, 0, 0, 4], [...  \n",
       "2  [[4, 3, 3, 0, 0, 7, 7, 5, 5, 6, 6, 1, 1, 2, 2,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the length of review tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 2191\n",
      "min: 1\n",
      "median: 14.0\n",
      "mean: 29.245665227875886\n",
      "Q3: 32.0\n",
      "Q1: 5.0\n",
      "Q(90%): 69.0\n"
     ]
    }
   ],
   "source": [
    "review_len = [len(row) for row in df[\"reviewTokens\"]]\n",
    "print(\"max:\", max(review_len))\n",
    "print(\"min:\", min(review_len))\n",
    "print(\"median:\", np.median(review_len))\n",
    "print(\"mean:\", np.mean(review_len))\n",
    "print(\"Q3:\", np.quantile(review_len, 0.75))\n",
    "print(\"Q1:\", np.quantile(review_len, 0.25))\n",
    "print(\"Q(90%):\", np.quantile(review_len, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_len = [len(row) for row in df[\"uniqueTokens\"]]\n",
    "sns.distplot(word_len, hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Review Score to Positive/Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify(df, target=\"overall\"):\n",
    "    '''\n",
    "    1. score 3 & 4 & 5 -> 1 (positive)\n",
    "    2. score 1 & 2 -> 0 (negative)\n",
    "    '''\n",
    "    y = []\n",
    "    for gp in df[target]:\n",
    "        if gp in [3, 4, 5]:\n",
    "            y.append(1)\n",
    "        elif gp in [1, 2]:\n",
    "            y.append(0)\n",
    "    assert len(y) == df.shape[0]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = reclassify(df, \"overall\")\n",
    "config.TARGET = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(df, train_percent=0.8, val_percent=0.1, set_seed=config.SEED):\n",
    "    n = df.shape[0] # get length of dataframe\n",
    "\n",
    "    # I will set the percentage of validation and test sets to be both 0.1\n",
    "    train_index, rest_index = train_test_split(range(n), train_size=0.8, random_state=config.SEED)\n",
    "    val_index, test_index = train_test_split(rest_index, train_size=(val_percent/(1-train_percent)), random_state=config.SEED) # 0.1/(1-0.8) = 0.1/0.2 = 0.5\n",
    "\n",
    "    # check if there is any intersection among all three sets\n",
    "    assert len(set(train_index + val_index + test_index)) == n\n",
    "\n",
    "    # get sub_datasets by random_split\n",
    "    np.random.seed(config.SEED)\n",
    "    train_df, val_df, test_df = df.iloc[train_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[val_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[test_index, :].reset_index(drop=True)\n",
    "\n",
    "    # check random_split works correctly\n",
    "    assert (len(train_df)+len(val_df)+len(test_df)) == n\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = dataset_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Build Vocabulary\n",
    "\n",
    "It's reasonable to build a vocabulary list from only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "\n",
    "for row in train_df[config.TOKENS]:\n",
    "    for word in row:\n",
    "        vocabulary.add_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. Imbalanced Dataset\n",
    "\n",
    "Note: I only make the training set balanced and leave the validation and test sets alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='y', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the imbalanced target variable\n",
    "sns.countplot(train_df[config.TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "def undersampling(df, target=config.TARGET, set_seed=config.SEED):\n",
    "    np.random.seed(set_seed)\n",
    "    df = df.groupby(target)\n",
    "    df = df.apply(lambda x: x.sample(df.size().min())).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 23638\n",
      "Length of test set: 23099\n"
     ]
    }
   ],
   "source": [
    "train_df = undersampling(train_df)\n",
    "print(\"Length of training set:\", train_df.shape[0])\n",
    "print(\"Length of test set:\", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, config, df, use_cuda, embeddings):\n",
    "        self.df = df\n",
    "        self.use_cuda = use_cuda\n",
    "        self.embeddings = embeddings\n",
    "        self.config = config\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tt = torch.cuda if self.use_cuda else torch\n",
    "        x = tt.FloatTensor(self.embeddings.get_embeddings(self.df[self.config.TOKENS][idx]))\n",
    "#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\n",
    "        y = tt.FloatTensor([self.df[self.config.TARGET][idx]])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the row length remains the same even we transform dataframe into graph dataset\n",
    "assert len(train_dataset)+len(val_dataset)+len(test_dataset) == len(train_df)+len(val_df)+len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T01:24:33.012811Z",
     "start_time": "2020-08-05T01:24:33.006012Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' For InMemoryDataset '''\n",
    "# def get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1):\n",
    "    \n",
    "#     # get length of subsets\n",
    "#     train_len = int(dataset.__len__()*0.8)\n",
    "#     val_len = int(dataset.__len__()*0.1)\n",
    "#     test_len = dataset.__len__()-train_len-val_len\n",
    "    \n",
    "#     # get sub_datasets by random_split\n",
    "#     seed_torch(config.SEED)\n",
    "#     train_dataset, val_dataset, test_dataset = random_split(dataset, (train_len, val_len, test_len))\n",
    "    \n",
    "#     # check random_split works correctly\n",
    "#     assert (len(train_dataset)+len(val_dataset)+len(test_dataset)) == dataset.__len__()\n",
    "    \n",
    "#     # get dataloaders\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "#     test_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader\n",
    "\n",
    "# train_loader, val_loader, test_loader = get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(config.SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class MultiClassBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, rnn_layer=2, dropout=0.3):\n",
    "        super(MultiClassBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = torch.transpose(x, dim0=1, dim1=0)\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: batch, num_seq, 2*hidden\n",
    "        out = self.relu(out)\n",
    "        print(out.size())\n",
    "        out = self.classify(out)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class BinaryBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, rnn_layer=2, dropout=0.3, hidden_transfer=\"last\"):\n",
    "        super(BinaryBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "        \n",
    "        assert hidden_transfer in [\"mean\", \"last\"]\n",
    "        self.hidden_transfer = hidden_transfer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, dim0=1, dim1=0) # x: batch x seq_len x embedding_dim -> seq_len x batch x embedding_dim\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: seq_len x batch x 2*embedding_dim\n",
    "        if self.hidden_transfer == \"mean\":\n",
    "            out = torch.mean(out, dim=0)\n",
    "        elif self.hidden_transfer == \"last\":\n",
    "            out = out[-1] # out: batch x 2*embedding_dim\n",
    "        out = self.relu(out) # out: batch x 2*embedding_dim\n",
    "        out = self.classify(out) # out: batch x n_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class BinaryRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, rnn_layer=2, dropout=0, hidden_transfer=\"last\"):\n",
    "        super(BinaryRNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.RNN(input_size=embedding_dim,\n",
    "                            hidden_size=128,\n",
    "                            num_layers=rnn_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(128, n_classes)\n",
    "        \n",
    "        assert hidden_transfer in [\"mean\", \"last\"]\n",
    "        self.hidden_transfer = hidden_transfer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, dim0=1, dim1=0) # x: batch x seq_len x embedding_dim -> seq_len x batch x embedding_dim\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: seq_len x batch x 2*embedding_dim\n",
    "        if self.hidden_transfer == \"mean\":\n",
    "            out = torch.mean(out, dim=0)\n",
    "        elif self.hidden_transfer == \"last\":\n",
    "            out = out[-1] # out: batch x 2*embedding_dim\n",
    "        out = self.relu(out) # out: batch x 2*embedding_dim\n",
    "        out = self.classify(out) # out: batch x n_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train & Validation & Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:34:54.271139Z",
     "start_time": "2020-08-05T06:34:54.268293Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(text, file_path, mode=\"a+\"):\n",
    "    print(text)\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(config):\n",
    "    texts = \"=== Settings ===\\n\"\n",
    "    var_config = vars(config)\n",
    "    for i in range(len(var_config)):\n",
    "        temp_text = \"{}: {}\\n\".format(list(var_config.keys())[i],\n",
    "                                      list(var_config.values())[i],\n",
    "                                     )\n",
    "        texts += temp_text\n",
    "    texts += \"============\\n\\n\"\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.217809Z",
     "start_time": "2020-08-05T06:49:58.207574Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config, train_loader, val_loader, model, criterion, optimizer):\n",
    "    global iteration, n_total, train_loss, n_bad_loss\n",
    "    global init, best_val_loss, stop\n",
    "\n",
    "    logs = \"=> EPOCH {}\".format(epoch)\n",
    "    write_log(logs, config.log_file, \"a+\")\n",
    "    \n",
    "    for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "        iteration += 1 # total iteration within all batches\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        \n",
    "        # train the model\n",
    "        model.train()\n",
    "#         for param in model.parameters():\n",
    "#             print(param.requires_grad)\n",
    "        output = model(batch[0])\n",
    "        \n",
    "        # loss function\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        # BP\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        # sum with the previous training loss for updating learning rate in the following\n",
    "        train_loss += batch_size * loss.item() # accumulated training loss; batch.num_graphs is the size of the batch\n",
    "        n_total += batch_size\n",
    "        \n",
    "#         # validation check\n",
    "        if iteration % config.log_every == 0:\n",
    "            train_loss /= n_total \n",
    "            val_loss = validate(config, val_loader, model, criterion)\n",
    "        \n",
    "            # save logs\n",
    "            logs = \"   % Time: {} | Iteration: {:5} | Batch: {:4}/{}\"\\\n",
    "                  \" | Train loss: {:.4f} | Val loss: {:.4f}\"\\\n",
    "                  .format(str(datetime.now()-init), iteration, batch_index+1,\n",
    "                          len(train_loader), train_loss, val_loss)\n",
    "            write_log(logs, config.log_file, \"a+\")\n",
    "\n",
    "            # test for val_loss improvement\n",
    "            n_total = train_loss = 0\n",
    "            if val_loss < best_val_loss: # update the best validation loss\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                torch.save(model.state_dict(), config.best_model) # save the checkpoint\n",
    "            else:\n",
    "                n_bad_loss += 1\n",
    "            \n",
    "            # update the learning rate if val loss does not improve for n_bad_loss times\n",
    "            if n_bad_loss == config.n_bad_loss:\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                adjust_learning_rate(optimizer, config.lr_decay)\n",
    "                new_lr = optimizer.param_groups[0]['lr']\n",
    "                \n",
    "                logs = \"=> Adjust learning rate to: {}\".format(new_lr)\n",
    "                write_log(logs, config.log_file, \"a+\")\n",
    "                \n",
    "                if new_lr < config.lr_min:\n",
    "                    stop = True\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.794219Z",
     "start_time": "2020-08-05T06:49:58.789194Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(config, val_loader, model, criterion):\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    dataset_size = 0\n",
    "    for batch in val_loader:\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        # train the model\n",
    "        output = model(batch[0])\n",
    "        loss = criterion(output, label)\n",
    "        val_loss += loss.data * batch_size\n",
    "    return val_loss / dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:08.304060Z",
     "start_time": "2020-08-05T07:27:08.298175Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(config, test_loader, model, threshold=0.5):\n",
    "    print(\"start testing...\")\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    label_list = []\n",
    "    prediction_list = []\n",
    "    predict_prob_list = []\n",
    "    \n",
    "    for batch in tqdm(test_loader):\n",
    "        \n",
    "        if config.N_CLASSES > 1:\n",
    "            label = batch[1].float()            \n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            output = model(batch)\n",
    "            _, prediction = torch.max(output, 1)\n",
    "            prediction = prediction.data.tolist()\n",
    "            prediction_list += prediction\n",
    "            \n",
    "        elif config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()            \n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            \n",
    "            output = model(batch[0]).squeeze(-1)\n",
    "            sigmoid = nn.Sigmoid() \n",
    "            output = sigmoid(output) # [-inf, inf] -> [0, 1]\n",
    "            prediction_list += [1 if o > threshold else 0 for o in output.data.tolist()]\n",
    "            predict_prob_list += output.data.tolist()\n",
    "        \n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(label_list, prediction_list))#.rename(columns=[\"1\",\"2\",\"3\",\"4\",\"5\"], index=[\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    # write the confusion matrix into the log\n",
    "    write_log(\"\\n{}\\n\\n{}\\n\".\\\n",
    "          format(\"=== Confusion Matrix ===\",\n",
    "                 confusion_matrix_df\n",
    "                 \n",
    "                ),\n",
    "          config.log_file,\n",
    "          \"a+\")\n",
    "    \n",
    "    sns.heatmap(confusion_matrix_df, annot=True)\n",
    "    \n",
    "    return label_list, prediction_list, predict_prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(config, model_test, name):\n",
    "    if name is None:\n",
    "        model_reloaded = config.best_model\n",
    "    else:\n",
    "        model_reloaded = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(name))\n",
    "    model_train = torch.load(model_reloaded)\n",
    "#     model_test = BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    model_test.load_state_dict(model_train)\n",
    "\n",
    "    return model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "batch_size: 32\n",
      "seed: 5\n",
      "epochs: 15\n",
      "cuda: True\n",
      "log_every: 200\n",
      "lr: 0.001\n",
      "lr_decay: 0.7\n",
      "lr_min: 1e-05\n",
      "n_bad_loss: 4\n",
      "clip: 2.3\n",
      "result_path: result/sequence/\n",
      "log_path: logs/sequence/\n",
      "USE_CUDA: True\n",
      "SEED: 123\n",
      "MODELING_FEATURE_PATH: dataset/full_dataset/modeling_features.json\n",
      "DATA_PATH: dataset/processed_dataset/\n",
      "NUM_FEATURES: 768\n",
      "N_CLASSES: 1\n",
      "TARGET: y\n",
      "TOKENS: reviewTokens\n",
      "dataset_used: straight_Musical_Instruments_5.json\n",
      "best_model: result/sequence/checkpoint/RNN_2020_08_25_05_19.pth\n",
      "log_file: logs/sequence/RNN_2020_08_25_05_19.txt\n",
      "============\n",
      "\n",
      "Start record at 2020-08-25 05:19:32.561824\n",
      "\n",
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ab8badc0ac4958ababbc0a04c056d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:05:13.886468 | Iteration:   200 | Batch:  200/739 | Train loss: 0.6937 | Val loss: 0.6930\n",
      "   % Time: 0:10:26.345067 | Iteration:   400 | Batch:  400/739 | Train loss: 0.6931 | Val loss: 0.6871\n",
      "   % Time: 0:15:37.637055 | Iteration:   600 | Batch:  600/739 | Train loss: 0.6933 | Val loss: 0.7004\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d54c36902a4d21bc9e5eebb12bb580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:20:49.788654 | Iteration:   800 | Batch:   61/739 | Train loss: 0.6928 | Val loss: 0.6732\n",
      "   % Time: 0:26:00.752848 | Iteration:  1000 | Batch:  261/739 | Train loss: 0.6933 | Val loss: 0.6953\n",
      "   % Time: 0:31:11.674491 | Iteration:  1200 | Batch:  461/739 | Train loss: 0.6927 | Val loss: 0.6959\n"
     ]
    }
   ],
   "source": [
    "''' initials '''\n",
    "# seed_torch(config.SEED)\n",
    "seed_torch(config.SEED)\n",
    "config.N_CLASSES = 1\n",
    "model_name = \"RNN\"\n",
    "config.batch_size = 32\n",
    "config.lr = 0.001\n",
    "\n",
    "''' rebuild dataset and dataloader due to edge_index '''\n",
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "''' initializing the model '''\n",
    "if config.N_CLASSES == 1:\n",
    "    # binary\n",
    "    model = BinaryRNN(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "else:\n",
    "    # MultiClass\n",
    "    model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "                             n_classes=config.N_CLASSES,\n",
    "                             dropout=0).to(device)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}_{}.pth\".format(model_name,\n",
    "                                                                                   datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                                  )\n",
    "                                )\n",
    "config.log_file = os.path.join(config.log_path, \"{}_{}.txt\".format(model_name,\n",
    "                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                            )\n",
    "                              )\n",
    "''' start training '''\n",
    "saved = True\n",
    "if 1 == 1:  # change to True to train\n",
    "    iteration = n_total = train_loss = n_bad_loss = 0\n",
    "    stop = False\n",
    "    best_val_loss = float(\"inf\")\n",
    "    init = datetime.now()\n",
    "    config.epochs = 15\n",
    "    config.log_every = 200\n",
    "    config.n_bad_loss = 4\n",
    "\n",
    "    if saved:\n",
    "        output_text = write_config(config) + \"Start record at {}\\n\".format(str(datetime.now()))\n",
    "        write_log(output_text,\n",
    "                  config.log_file,\n",
    "                  \"w+\")\n",
    "        \n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_torch(config.SEED)\n",
    "# config.N_CLASSES = 1\n",
    "\n",
    "# if config.N_CLASSES == 1:\n",
    "#     # binary\n",
    "#     model = BinaryBiLSTM(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "#     criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# else:\n",
    "#     # MultiClass\n",
    "#     model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "#                              n_classes=config.N_CLASSES,\n",
    "#                              dropout=0).to(device)\n",
    "#     criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "# config.best_model = os.path.join(config.result_path, \"checkpoint/neighbor{}_{}_{}.pth\".format(3,\n",
    "#                                                                                              \"LSTM\",\n",
    "#                                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                             )\n",
    "#                                 )\n",
    "# config.log_file = os.path.join(config.log_path, \"neighbor{}_{}_{}.txt\".format(3,\n",
    "#                                                                               \"LSTM\",\n",
    "#                                                                               datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                )\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:22:47.974384Z",
     "start_time": "2020-08-05T07:22:47.972571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79615820f5724ce59dbeca8ba2ffe611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:01:46.178220 | Iteration:   100 | Batch:  100/667 | Train loss: 0.7400 | Val loss: 0.6931\n",
      "   % Time: 0:03:29.330737 | Iteration:   200 | Batch:  200/667 | Train loss: 0.6942 | Val loss: 0.6950\n",
      "   % Time: 0:05:12.249364 | Iteration:   300 | Batch:  300/667 | Train loss: 0.6939 | Val loss: 0.6931\n",
      "   % Time: 0:06:55.106757 | Iteration:   400 | Batch:  400/667 | Train loss: 0.6938 | Val loss: 0.6932\n",
      "   % Time: 0:08:37.712439 | Iteration:   500 | Batch:  500/667 | Train loss: 0.6938 | Val loss: 0.6944\n",
      "   % Time: 0:10:20.419047 | Iteration:   600 | Batch:  600/667 | Train loss: 0.6936 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d0af5c1b0749ffaedcd8cf1b569ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:12:03.191009 | Iteration:   700 | Batch:   33/667 | Train loss: 0.6935 | Val loss: 0.6929\n",
      "   % Time: 0:13:46.022992 | Iteration:   800 | Batch:  133/667 | Train loss: 0.6932 | Val loss: 0.6945\n",
      "   % Time: 0:15:28.779864 | Iteration:   900 | Batch:  233/667 | Train loss: 0.6936 | Val loss: 0.6940\n",
      "   % Time: 0:17:11.843233 | Iteration:  1000 | Batch:  333/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:18:54.798077 | Iteration:  1100 | Batch:  433/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:20:37.708624 | Iteration:  1200 | Batch:  533/667 | Train loss: 0.6931 | Val loss: 0.6925\n",
      "   % Time: 0:22:20.965800 | Iteration:  1300 | Batch:  633/667 | Train loss: 0.6931 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64836e8c9e204fce9fb82f97a2e9e9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:24:03.325921 | Iteration:  1400 | Batch:   66/667 | Train loss: 0.6933 | Val loss: 0.6925\n",
      "   % Time: 0:25:46.083991 | Iteration:  1500 | Batch:  166/667 | Train loss: 0.6928 | Val loss: 0.6926\n",
      "   % Time: 0:27:28.930592 | Iteration:  1600 | Batch:  266/667 | Train loss: 0.6933 | Val loss: 0.6924\n",
      "   % Time: 0:29:12.092595 | Iteration:  1700 | Batch:  366/667 | Train loss: 0.6929 | Val loss: 0.6920\n",
      "   % Time: 0:30:54.998296 | Iteration:  1800 | Batch:  466/667 | Train loss: 0.6929 | Val loss: 0.6927\n",
      "   % Time: 0:32:37.740151 | Iteration:  1900 | Batch:  566/667 | Train loss: 0.6920 | Val loss: 0.6929\n",
      "   % Time: 0:34:20.795365 | Iteration:  2000 | Batch:  666/667 | Train loss: 0.6926 | Val loss: 0.6918\n",
      "\n",
      "=> EPOCH 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb74773c94948dbbb36404b452b003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:36:03.499585 | Iteration:  2100 | Batch:   99/667 | Train loss: 0.6932 | Val loss: 0.6923\n",
      "   % Time: 0:37:46.510389 | Iteration:  2200 | Batch:  199/667 | Train loss: 0.6927 | Val loss: 0.6942\n",
      "   % Time: 0:39:29.271913 | Iteration:  2300 | Batch:  299/667 | Train loss: 0.6926 | Val loss: 0.6916\n",
      "   % Time: 0:41:12.422652 | Iteration:  2400 | Batch:  399/667 | Train loss: 0.6917 | Val loss: 0.6916\n",
      "   % Time: 0:42:55.318922 | Iteration:  2500 | Batch:  499/667 | Train loss: 0.6925 | Val loss: 0.6914\n",
      "   % Time: 0:44:38.159164 | Iteration:  2600 | Batch:  599/667 | Train loss: 0.6925 | Val loss: 0.6919\n",
      "\n",
      "=> EPOCH 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6945208b47404fdba1436b9863a54322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:46:20.764817 | Iteration:  2700 | Batch:   32/667 | Train loss: 0.6918 | Val loss: 0.6915\n",
      "   % Time: 0:48:03.926512 | Iteration:  2800 | Batch:  132/667 | Train loss: 0.6918 | Val loss: 0.6919\n",
      "   % Time: 0:49:46.724723 | Iteration:  2900 | Batch:  232/667 | Train loss: 0.6924 | Val loss: 0.6915\n",
      "   % Time: 0:51:29.475810 | Iteration:  3000 | Batch:  332/667 | Train loss: 0.6918 | Val loss: 0.6916\n",
      "   % Time: 0:53:12.400121 | Iteration:  3100 | Batch:  432/667 | Train loss: 0.6931 | Val loss: 0.6916\n",
      "   % Time: 0:54:55.354984 | Iteration:  3200 | Batch:  532/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 0:56:39.002330 | Iteration:  3300 | Batch:  632/667 | Train loss: 0.6928 | Val loss: 0.6916\n",
      "\n",
      "=> EPOCH 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b480b7cd31a441880f2149243d77fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:58:21.822922 | Iteration:  3400 | Batch:   65/667 | Train loss: 0.6919 | Val loss: 0.6917\n",
      "   % Time: 1:00:04.773279 | Iteration:  3500 | Batch:  165/667 | Train loss: 0.6921 | Val loss: 0.6914\n",
      "   % Time: 1:01:47.408068 | Iteration:  3600 | Batch:  265/667 | Train loss: 0.6918 | Val loss: 0.6913\n",
      "   % Time: 1:03:30.645946 | Iteration:  3700 | Batch:  365/667 | Train loss: 0.6919 | Val loss: 0.6915\n",
      "   % Time: 1:05:14.800460 | Iteration:  3800 | Batch:  465/667 | Train loss: 0.6916 | Val loss: 0.6911\n",
      "   % Time: 1:06:58.463083 | Iteration:  3900 | Batch:  565/667 | Train loss: 0.6919 | Val loss: 0.6916\n",
      "   % Time: 1:08:41.594795 | Iteration:  4000 | Batch:  665/667 | Train loss: 0.6929 | Val loss: 0.6913\n",
      "\n",
      "=> EPOCH 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893e08e3e4bc4716b7054915fa0acfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:10:24.484646 | Iteration:  4100 | Batch:   98/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 1:12:07.046520 | Iteration:  4200 | Batch:  198/667 | Train loss: 0.6919 | Val loss: 0.6914\n",
      "   % Time: 1:13:49.616556 | Iteration:  4300 | Batch:  298/667 | Train loss: 0.6917 | Val loss: 0.6912\n",
      "   % Time: 1:15:32.444589 | Iteration:  4400 | Batch:  398/667 | Train loss: 0.6913 | Val loss: 0.6908\n",
      "   % Time: 1:17:15.573810 | Iteration:  4500 | Batch:  498/667 | Train loss: 0.6914 | Val loss: 0.6909\n",
      "   % Time: 1:18:58.556091 | Iteration:  4600 | Batch:  598/667 | Train loss: 0.6912 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788b04bd80d41d28bdd711d0b3bf7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:20:41.073296 | Iteration:  4700 | Batch:   31/667 | Train loss: 0.6920 | Val loss: 0.6909\n",
      "   % Time: 1:22:23.977725 | Iteration:  4800 | Batch:  131/667 | Train loss: 0.6911 | Val loss: 0.6912\n",
      "   % Time: 1:24:06.920420 | Iteration:  4900 | Batch:  231/667 | Train loss: 0.6903 | Val loss: 0.6909\n",
      "   % Time: 1:25:49.773948 | Iteration:  5000 | Batch:  331/667 | Train loss: 0.6910 | Val loss: 0.6914\n",
      "   % Time: 1:27:32.880611 | Iteration:  5100 | Batch:  431/667 | Train loss: 0.6911 | Val loss: 0.6917\n",
      "   % Time: 1:29:16.246776 | Iteration:  5200 | Batch:  531/667 | Train loss: 0.6906 | Val loss: 0.6913\n",
      "   % Time: 1:30:59.080945 | Iteration:  5300 | Batch:  631/667 | Train loss: 0.6915 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478364f5fe384952a127c3ef0db17e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:32:41.803908 | Iteration:  5400 | Batch:   64/667 | Train loss: 0.6911 | Val loss: 0.6914\n",
      "=> Adjust learning rate to: 0.006999999999999999\n",
      "   % Time: 1:34:24.458104 | Iteration:  5500 | Batch:  164/667 | Train loss: 0.6895 | Val loss: 0.6916\n",
      "   % Time: 1:36:07.163432 | Iteration:  5600 | Batch:  264/667 | Train loss: 0.6908 | Val loss: 0.6913\n",
      "   % Time: 1:37:50.319805 | Iteration:  5700 | Batch:  364/667 | Train loss: 0.6914 | Val loss: 0.6912\n",
      "   % Time: 1:39:33.526270 | Iteration:  5800 | Batch:  464/667 | Train loss: 0.6895 | Val loss: 0.6910\n",
      "   % Time: 1:41:16.676685 | Iteration:  5900 | Batch:  564/667 | Train loss: 0.6906 | Val loss: 0.6911\n",
      "   % Time: 1:42:59.682476 | Iteration:  6000 | Batch:  664/667 | Train loss: 0.6901 | Val loss: 0.6910\n",
      "\n",
      "=> EPOCH 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bae6ee69d114834a5c8c7602c9ba8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:44:42.483787 | Iteration:  6100 | Batch:   97/667 | Train loss: 0.6890 | Val loss: 0.6912\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-77791d40d758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \"w+\")\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5416212a9406>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> EPOCH {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# total iteration within all batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5687f46f2bd9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOKENS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/cathay/src/preprocessing/feature_engineering/bert_embedding.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, row_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                           \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                           \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                           \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                                          )\n\u001b[1;32m     33\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# however, we do not take cls & \\cls into consideration when building the embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id_with_added_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# saved = True\n",
    "# if 1 == 1:  # change to True to train\n",
    "#     iteration = n_total = train_loss = n_bad_loss = 0\n",
    "#     stop = False\n",
    "#     best_val_loss = float(\"inf\")\n",
    "#     init = datetime.now()\n",
    "#     config.epochs = 10\n",
    "# #     config.n_bad_loss 4\n",
    "#     if saved:\n",
    "#         write_log(\"Start record at {}\\n\".format(str(datetime.now())),\n",
    "#                   config.log_file,\n",
    "#                   \"w+\")\n",
    "#     for epoch in range(1, config.epochs+1):\n",
    "#         train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "#         if stop:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:10.966688Z",
     "start_time": "2020-08-05T07:27:10.964582Z"
    }
   },
   "source": [
    "## 8. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_name = config.best_model.split(\"/\")[-1][:-4] # default\n",
    "result_name = \"\"\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(result_name))\n",
    "config.log_file = os.path.join(config.log_path, \"{}.txt\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_load(config, \n",
    "                        BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device),\n",
    "                        name=result_name,\n",
    "                       )\n",
    "y_true, y_pred, y_prob = test(config, test_loader, model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.10      0.18     21307\n",
      "         1.0       0.51      0.93      0.66     21336\n",
      "\n",
      "    accuracy                           0.52     42643\n",
      "   macro avg       0.56      0.52      0.42     42643\n",
      "weighted avg       0.56      0.52      0.42     42643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# write the report\n",
    "write_log(\"\\n{}\\n\\n{}\\n\".\\\n",
    "          format(\"=== Classification Report ===\",\n",
    "                 report\n",
    "                ),\n",
    "          config.log_file,\n",
    "          \"a+\")\n",
    "\n",
    "# print\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. Saving Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.PREDICTED_RESULT = os.path.join(\"result/graph/prediction\", \"{}.pkl\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predicted result\n",
    "with open(config.PREDICTED_RESULT, 'wb') as f:\n",
    "    pickle.dump([y_true, y_pred, y_prob], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.PREDICTED_RESULT, 'rb') as f:\n",
    "    y_true, y_pred, y_prob = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.log_file, \"r+\") as file:\n",
    "    logs = file.readlines()\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    for row in logs:\n",
    "        if len(row.split(\"|\")) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            train_loss.append(float(row.split(\"|\")[-2].strip().split(\" \")[-1]))\n",
    "            val_loss.append(float(row.split(\"|\")[-1].strip().split(\" \")[-1]))\n",
    "    assert len(train_loss) == len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(train_loss)), train_loss, '-b', label='train')\n",
    "ax.plot(range(len(val_loss)), val_loss, '--r', label='validation')\n",
    "leg = ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
