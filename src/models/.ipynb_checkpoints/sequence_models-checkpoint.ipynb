{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:23.407418Z",
     "start_time": "2020-08-05T07:13:23.398377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /scratch/kll482/cathay\n",
      "Config Sections: ['text_cleaning', 'feature_engineering', 'graph_models']\n"
     ]
    }
   ],
   "source": [
    "''' root '''\n",
    "import os\n",
    "os.chdir(\"/scratch/kll482/cathay\")\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/scratch/kll482/cathay/\")\n",
    "\n",
    "''' config '''\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"config/config.ini\")\n",
    "print(\"Config Sections:\", config.sections())\n",
    "args = config[\"graph_models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:15:33.614186Z",
     "start_time": "2020-08-05T07:15:33.609071Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' packages '''\n",
    "# import torch, torchvision\n",
    "# import pandas as pd, numpy as np\n",
    "# import argparse\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# # from torch_geometric.data.InMemoryDataset import collate\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' packages '''\n",
    "# 1. models\n",
    "import torch, torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 2. others\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import pandas as pd, numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter(\"logs/graph/\")\n",
    "\n",
    "# 3. custom\n",
    "from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "from src.utils.vocabulary import Vocabulary\n",
    "from src.utils.pipeline import Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initial Variables & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:28.592867Z",
     "start_time": "2020-08-05T07:13:28.589113Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Hyperparameters '''\n",
    "parser = {\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 5, # random seed\n",
    "    \"epochs\": 5,\n",
    "    \"cuda\": True, # use cuda or not\n",
    "    \"log_every\": 100,\n",
    "    \"lr\": 0.01,  # initial learning rate\n",
    "    \"lr_decay\": 0.7,  # decay lr when not observing improvement in val_loss\n",
    "    \"lr_min\": 1e-5,  # stop when lr is too low\n",
    "    \"n_bad_loss\": 4,  # number of bad val_loss before decaying\n",
    "    \"clip\": 2.3,\n",
    "    \"result_path\": \"result/sequence/\",  # path to save models\n",
    "    \"log_path\": \"logs/sequence/\",\n",
    "}\n",
    "config = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' General '''\n",
    "config.USE_CUDA = 1 # bool(int(args[\"use_cuda\"]))\n",
    "config.SEED = int(args[\"set_seed\"])\n",
    "config.MODELING_FEATURE_PATH = args[\"modeling_feature_path\"]\n",
    "config.DATA_PATH = args[\"data_path\"]\n",
    "config.NUM_FEATURES = 768\n",
    "config.N_CLASSES = 1\n",
    "config.TARGET = \"overall\"\n",
    "config.TOKENS = \"reviewTokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. CUDA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.284510Z",
     "start_time": "2020-08-05T07:13:29.276557Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config.USE_CUDA = config.USE_CUDA and torch.cuda.is_available()\n",
    "print(\"cuda on: \", config.USE_CUDA)\n",
    "if config.USE_CUDA:\n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    torch.manual_seed(config.SEED)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if config.USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.480321Z",
     "start_time": "2020-08-05T07:13:29.476385Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=config.SEED):\n",
    "    #random.seed(seed)\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:14:27.559723Z",
     "start_time": "2020-08-05T07:13:30.485201Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"read the datasets...\")\n",
    "files = []\n",
    "# file_path = [file for file in os.listdir(config.DATA_PATH) if file.endswith(\".json\")]\n",
    "file_path = ['Video_Games_5.json', 'Musical_Instruments_5.json']\n",
    "for file in file_path:    \n",
    "    files.append(pd.read_json(os.path.join(config.DATA_PATH, file)))\n",
    "    \n",
    "df = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the length of review tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_len = [len(row) for row in df[\"reviewTokens\"]]\n",
    "print(\"max:\", max(review_len))\n",
    "print(\"min:\", min(review_len))\n",
    "print(\"median:\", np.median(review_len))\n",
    "print(\"mean:\", np.mean(review_len))\n",
    "print(\"Q3:\", np.quantile(review_len, 0.75))\n",
    "print(\"Q1:\", np.quantile(review_len, 0.25))\n",
    "print(\"Q(90%):\", np.quantile(review_len, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_len = [len(row) for row in df[\"uniqueTokens\"]]\n",
    "sns.distplot(word_len, hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Review Score to Positive/Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify(df, target=\"overall\"):\n",
    "    '''\n",
    "    1. score 3 & 4 & 5 -> 1 (positive)\n",
    "    2. score 1 & 2 -> 0 (negative)\n",
    "    '''\n",
    "    y = []\n",
    "    for gp in df[target]:\n",
    "        if gp in [3, 4, 5]:\n",
    "            y.append(1)\n",
    "        elif gp in [1, 2]:\n",
    "            y.append(0)\n",
    "    assert len(y) == df.shape[0]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = reclassify(df, \"overall\")\n",
    "config.TARGET = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(df, train_percent=0.8, val_percent=0.1, set_seed=config.SEED):\n",
    "    n = df.shape[0] # get length of dataframe\n",
    "\n",
    "    # I will set the percentage of validation and test sets to be both 0.1\n",
    "    train_index, rest_index = train_test_split(range(n), train_size=0.8, random_state=config.SEED)\n",
    "    val_index, test_index = train_test_split(rest_index, train_size=(val_percent/(1-train_percent)), random_state=config.SEED) # 0.1/(1-0.8) = 0.1/0.2 = 0.5\n",
    "\n",
    "    # check if there is any intersection among all three sets\n",
    "    assert len(set(train_index + val_index + test_index)) == n\n",
    "\n",
    "    # get sub_datasets by random_split\n",
    "    np.random.seed(config.SEED)\n",
    "    train_df, val_df, test_df = df.iloc[train_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[val_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[test_index, :].reset_index(drop=True)\n",
    "\n",
    "    # check random_split works correctly\n",
    "    assert (len(train_df)+len(val_df)+len(test_df)) == n\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = dataset_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Build Vocabulary\n",
    "\n",
    "It's reasonable to build a vocabulary list from only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "\n",
    "for row in train_df[config.TOKENS]:\n",
    "    for word in row:\n",
    "        vocabulary.add_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. Imbalanced Dataset\n",
    "\n",
    "Note: I only make the training set balanced and leave the validation and test sets alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the imbalanced target variable\n",
    "sns.countplot(train_df[config.TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "def undersampling(df, target=config.TARGET, set_seed=config.SEED):\n",
    "    np.random.seed(set_seed)\n",
    "    df = df.groupby(target)\n",
    "    df = df.apply(lambda x: x.sample(df.size().min())).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = undersampling(train_df)\n",
    "print(\"Length of training set:\", train_df.shape[0])\n",
    "print(\"Length of test set:\", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, config, df, use_cuda, embeddings):\n",
    "        self.df = df\n",
    "        self.use_cuda = use_cuda\n",
    "        self.embeddings = embeddings\n",
    "        self.config = config\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tt = torch.cuda if self.use_cuda else torch\n",
    "        x = tt.FloatTensor(self.embeddings.get_embeddings(self.df[self.config.TOKENS][idx]))\n",
    "#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\n",
    "        y = tt.FloatTensor([self.df[self.config.TARGET][idx]])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the row length remains the same even we transform dataframe into graph dataset\n",
    "assert len(train_dataset)+len(val_dataset)+len(test_dataset) == len(train_df)+len(val_df)+len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T01:24:33.012811Z",
     "start_time": "2020-08-05T01:24:33.006012Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' For InMemoryDataset '''\n",
    "# def get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1):\n",
    "    \n",
    "#     # get length of subsets\n",
    "#     train_len = int(dataset.__len__()*0.8)\n",
    "#     val_len = int(dataset.__len__()*0.1)\n",
    "#     test_len = dataset.__len__()-train_len-val_len\n",
    "    \n",
    "#     # get sub_datasets by random_split\n",
    "#     seed_torch(config.SEED)\n",
    "#     train_dataset, val_dataset, test_dataset = random_split(dataset, (train_len, val_len, test_len))\n",
    "    \n",
    "#     # check random_split works correctly\n",
    "#     assert (len(train_dataset)+len(val_dataset)+len(test_dataset)) == dataset.__len__()\n",
    "    \n",
    "#     # get dataloaders\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "#     test_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader\n",
    "\n",
    "# train_loader, val_loader, test_loader = get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(config.SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class MultiClassBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, lstm_layer=2, dropout=0.3):\n",
    "        super(MultiClassBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = torch.transpose(x, dim0=1, dim1=0)\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: batch, num_seq, 2*hidden\n",
    "        out = self.relu(out)\n",
    "        print(out.size())\n",
    "        out = self.classify(out)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class BinaryBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, lstm_layer=2, dropout=0.3, hidden_transfer=\"last\"):\n",
    "        super(BinaryBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "        \n",
    "        assert hidden_transfer in [\"mean\", \"last\"]\n",
    "        self.hidden_transfer = hidden_transfer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, dim0=1, dim1=0) # x: batch x seq_len x embedding_dim -> seq_len x batch x embedding_dim\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: seq_len x batch x 2*embedding_dim\n",
    "        if self.hidden_transfer == \"mean\":\n",
    "            out = torch.mean(out, dim=0)\n",
    "        elif self.hidden_transfer == \"last\":\n",
    "            out = out[-1] # out: batch x 2*embedding_dim\n",
    "        out = self.relu(out) # out: batch x 2*embedding_dim\n",
    "        out = self.classify(out) # out: batch x n_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class BinaryRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, lstm_layer=2, dropout=0.3, hidden_transfer=\"last\"):\n",
    "        super(BinaryRNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.RNN(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "        \n",
    "        assert hidden_transfer in [\"mean\", \"last\"]\n",
    "        self.hidden_transfer = hidden_transfer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, dim0=1, dim1=0) # x: batch x seq_len x embedding_dim -> seq_len x batch x embedding_dim\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: seq_len x batch x 2*embedding_dim\n",
    "        if self.hidden_transfer == \"mean\":\n",
    "            out = torch.mean(out, dim=0)\n",
    "        elif self.hidden_transfer == \"last\":\n",
    "            out = out[-1] # out: batch x 2*embedding_dim\n",
    "        out = self.relu(out) # out: batch x 2*embedding_dim\n",
    "        out = self.classify(out) # out: batch x n_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train & Validation & Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:34:54.271139Z",
     "start_time": "2020-08-05T06:34:54.268293Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(text, file_path, mode=\"a+\"):\n",
    "    print(text)\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(config):\n",
    "    texts = \"=== Settings ===\\n\"\n",
    "    var_config = vars(config)\n",
    "    for i in range(len(var_config)):\n",
    "        temp_text = \"{}: {}\\n\".format(list(var_config.keys())[i],\n",
    "                                      list(var_config.values())[i],\n",
    "                                     )\n",
    "        texts += temp_text\n",
    "    texts += \"============\\n\\n\"\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.217809Z",
     "start_time": "2020-08-05T06:49:58.207574Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config, train_loader, val_loader, model, criterion, optimizer):\n",
    "    global iteration, n_total, train_loss, n_bad_loss\n",
    "    global init, best_val_loss, stop\n",
    "\n",
    "    logs = \"=> EPOCH {}\".format(epoch)\n",
    "    write_log(logs, config.log_file, \"a+\")\n",
    "    \n",
    "    for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "        iteration += 1 # total iteration within all batches\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        \n",
    "        # train the model\n",
    "        model.train()\n",
    "#         for param in model.parameters():\n",
    "#             print(param.requires_grad)\n",
    "        output = model(batch[0])\n",
    "        \n",
    "        # loss function\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        # BP\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        # sum with the previous training loss for updating learning rate in the following\n",
    "        train_loss += batch_size * loss.item() # accumulated training loss; batch.num_graphs is the size of the batch\n",
    "        n_total += batch_size\n",
    "        \n",
    "#         # validation check\n",
    "        if iteration % config.log_every == 0:\n",
    "            train_loss /= n_total \n",
    "            val_loss = validate(config, val_loader, model, criterion)\n",
    "        \n",
    "            # save logs\n",
    "            logs = \"   % Time: {} | Iteration: {:5} | Batch: {:4}/{}\"\\\n",
    "                  \" | Train loss: {:.4f} | Val loss: {:.4f}\"\\\n",
    "                  .format(str(datetime.now()-init), iteration, batch_index+1,\n",
    "                          len(train_loader), train_loss, val_loss)\n",
    "            write_log(logs, config.log_file, \"a+\")\n",
    "\n",
    "            # test for val_loss improvement\n",
    "            n_total = train_loss = 0\n",
    "            if val_loss < best_val_loss: # update the best validation loss\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                torch.save(model.state_dict(), config.best_model) # save the checkpoint\n",
    "            else:\n",
    "                n_bad_loss += 1\n",
    "            \n",
    "            # update the learning rate if val loss does not improve for n_bad_loss times\n",
    "            if n_bad_loss == config.n_bad_loss:\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                adjust_learning_rate(optimizer, config.lr_decay)\n",
    "                new_lr = optimizer.param_groups[0]['lr']\n",
    "                \n",
    "                logs = \"=> Adjust learning rate to: {}\".format(new_lr)\n",
    "                write_log(logs, config.log_file, \"a+\")\n",
    "                \n",
    "                if new_lr < config.lr_min:\n",
    "                    stop = True\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.794219Z",
     "start_time": "2020-08-05T06:49:58.789194Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(config, val_loader, model, criterion):\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    dataset_size = 0\n",
    "    for batch in val_loader:\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        # train the model\n",
    "        output = model(batch[0])\n",
    "        loss = criterion(output, label)\n",
    "        val_loss += loss.data * batch_size\n",
    "    return val_loss / dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:08.304060Z",
     "start_time": "2020-08-05T07:27:08.298175Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(config, test_loader, model, threshold=0.5):\n",
    "    print(\"start testing...\")\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    label_list = []\n",
    "    prediction_list = []\n",
    "        \n",
    "    if config.N_CLASSES > 1:\n",
    "        for batch in tqdm(test_loader):\n",
    "            # binary\n",
    "            label = batch[1].long()\n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            \n",
    "            output = model(batch[0])\n",
    "            _, prediction = torch.max(output, 1)\n",
    "            prediction = prediction.data.tolist()\n",
    "            prediction_list += prediction\n",
    "            \n",
    "    elif config.N_CLASSES == 1:\n",
    "        for batch in tqdm(test_loader):\n",
    "            label = batch[1].float()            \n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            \n",
    "            output = model(batch[0]).squeeze(-1)\n",
    "            sigmoid = nn.Sigmoid() \n",
    "            output = sigmoid(output) # [-inf, inf] -> [0, 1]\n",
    "            prediction_list += [1 if output > threshold else 0]\n",
    "   \n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(label_list, prediction_list))#.rename(columns=[\"1\",\"2\",\"3\",\"4\",\"5\"], index=[\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    print(confusion_matrix_df)\n",
    "    sns.heatmap(confusion_matrix_df, annot=True)\n",
    "    \n",
    "    return label_list, prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(config, model_test, name):\n",
    "    if name is None:\n",
    "        model_reloaded = config.best_model\n",
    "    else:\n",
    "        model_reloaded = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(name))\n",
    "    model_train = torch.load(model_reloaded)\n",
    "#     model_test = BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    model_test.load_state_dict(model_train)\n",
    "\n",
    "    return model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "batch_size: 64\n",
      "seed: 5\n",
      "epochs: 15\n",
      "cuda: True\n",
      "log_every: 500\n",
      "lr: 0.001\n",
      "lr_decay: 0.7\n",
      "lr_min: 1e-05\n",
      "n_bad_loss: 4\n",
      "clip: 2.3\n",
      "result_path: result/sequence/\n",
      "log_path: logs/sequence/\n",
      "USE_CUDA: True\n",
      "SEED: 123\n",
      "MODELING_FEATURE_PATH: dataset/full_dataset/modeling_features.json\n",
      "DATA_PATH: dataset/processed_dataset/\n",
      "NUM_FEATURES: 768\n",
      "N_CLASSES: 1\n",
      "TARGET: y\n",
      "TOKENS: reviewTokens\n",
      "best_model: result/sequence/checkpoint/BiLSTM_2020_08_24_04_40.pth\n",
      "log_file: logs/sequence/BiLSTM_2020_08_24_04_40.txt\n",
      "============\n",
      "\n",
      "Start record at 2020-08-24 04:40:50.345092\n",
      "\n",
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b99fff789542d4b437228b9177e1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:09:37.781457 | Iteration:   500 | Batch:  500/1743 | Train loss: 0.6779 | Val loss: 0.5929\n",
      "   % Time: 0:19:17.214254 | Iteration:  1000 | Batch: 1000/1743 | Train loss: 0.6868 | Val loss: 0.6600\n",
      "   % Time: 0:28:54.600647 | Iteration:  1500 | Batch: 1500/1743 | Train loss: 0.6853 | Val loss: 0.6587\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d395431d78409f8dded44ee5c301e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:38:33.100316 | Iteration:  2000 | Batch:  257/1743 | Train loss: 0.6801 | Val loss: 0.7040\n",
      "   % Time: 0:48:12.901609 | Iteration:  2500 | Batch:  757/1743 | Train loss: 0.6731 | Val loss: 0.6978\n",
      "=> Adjust learning rate to: 0.0007\n",
      "   % Time: 0:57:53.096547 | Iteration:  3000 | Batch: 1257/1743 | Train loss: 0.6842 | Val loss: 0.6475\n",
      "\n",
      "=> EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f59913c64848bdbf519a5e77ce7e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:07:30.810014 | Iteration:  3500 | Batch:   14/1743 | Train loss: 0.6783 | Val loss: 0.6813\n"
     ]
    }
   ],
   "source": [
    "''' initials '''\n",
    "# seed_torch(config.SEED)\n",
    "seed_torch(config.SEED)\n",
    "config.N_CLASSES = 1\n",
    "model_name = \"BiLSTM\"\n",
    "\n",
    "''' rebuild dataset and dataloader due to edge_index '''\n",
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=134),\n",
    "                       )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "''' initializing the model '''\n",
    "if config.N_CLASSES == 1:\n",
    "    # binary\n",
    "    model = BinaryBiLSTM(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "else:\n",
    "    # MultiClass\n",
    "    model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "                             n_classes=config.N_CLASSES,\n",
    "                             dropout=0).to(device)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}_{}.pth\".format(model_name,\n",
    "                                                                                   datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                                  )\n",
    "                                )\n",
    "config.log_file = os.path.join(config.log_path, \"{}_{}.txt\".format(model_name,\n",
    "                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                            )\n",
    "                              )\n",
    "''' start training '''\n",
    "saved = True\n",
    "if 1 == 1:  # change to True to train\n",
    "    iteration = n_total = train_loss = n_bad_loss = 0\n",
    "    stop = False\n",
    "    best_val_loss = float(\"inf\")\n",
    "    init = datetime.now()\n",
    "    config.epochs = 15\n",
    "    config.log_every = 500\n",
    "    config.lr = 0.001\n",
    "    config.n_bad_loss = 4\n",
    "\n",
    "    if saved:\n",
    "        output_text = write_config(config) + \"Start record at {}\\n\".format(str(datetime.now()))\n",
    "        write_log(output_text,\n",
    "                  config.log_file,\n",
    "                  \"w+\")\n",
    "        \n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_torch(config.SEED)\n",
    "# config.N_CLASSES = 1\n",
    "\n",
    "# if config.N_CLASSES == 1:\n",
    "#     # binary\n",
    "#     model = BinaryBiLSTM(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "#     criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# else:\n",
    "#     # MultiClass\n",
    "#     model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "#                              n_classes=config.N_CLASSES,\n",
    "#                              dropout=0).to(device)\n",
    "#     criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "# config.best_model = os.path.join(config.result_path, \"checkpoint/neighbor{}_{}_{}.pth\".format(3,\n",
    "#                                                                                              \"LSTM\",\n",
    "#                                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                             )\n",
    "#                                 )\n",
    "# config.log_file = os.path.join(config.log_path, \"neighbor{}_{}_{}.txt\".format(3,\n",
    "#                                                                               \"LSTM\",\n",
    "#                                                                               datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                )\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:22:47.974384Z",
     "start_time": "2020-08-05T07:22:47.972571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79615820f5724ce59dbeca8ba2ffe611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:01:46.178220 | Iteration:   100 | Batch:  100/667 | Train loss: 0.7400 | Val loss: 0.6931\n",
      "   % Time: 0:03:29.330737 | Iteration:   200 | Batch:  200/667 | Train loss: 0.6942 | Val loss: 0.6950\n",
      "   % Time: 0:05:12.249364 | Iteration:   300 | Batch:  300/667 | Train loss: 0.6939 | Val loss: 0.6931\n",
      "   % Time: 0:06:55.106757 | Iteration:   400 | Batch:  400/667 | Train loss: 0.6938 | Val loss: 0.6932\n",
      "   % Time: 0:08:37.712439 | Iteration:   500 | Batch:  500/667 | Train loss: 0.6938 | Val loss: 0.6944\n",
      "   % Time: 0:10:20.419047 | Iteration:   600 | Batch:  600/667 | Train loss: 0.6936 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d0af5c1b0749ffaedcd8cf1b569ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:12:03.191009 | Iteration:   700 | Batch:   33/667 | Train loss: 0.6935 | Val loss: 0.6929\n",
      "   % Time: 0:13:46.022992 | Iteration:   800 | Batch:  133/667 | Train loss: 0.6932 | Val loss: 0.6945\n",
      "   % Time: 0:15:28.779864 | Iteration:   900 | Batch:  233/667 | Train loss: 0.6936 | Val loss: 0.6940\n",
      "   % Time: 0:17:11.843233 | Iteration:  1000 | Batch:  333/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:18:54.798077 | Iteration:  1100 | Batch:  433/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:20:37.708624 | Iteration:  1200 | Batch:  533/667 | Train loss: 0.6931 | Val loss: 0.6925\n",
      "   % Time: 0:22:20.965800 | Iteration:  1300 | Batch:  633/667 | Train loss: 0.6931 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64836e8c9e204fce9fb82f97a2e9e9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:24:03.325921 | Iteration:  1400 | Batch:   66/667 | Train loss: 0.6933 | Val loss: 0.6925\n",
      "   % Time: 0:25:46.083991 | Iteration:  1500 | Batch:  166/667 | Train loss: 0.6928 | Val loss: 0.6926\n",
      "   % Time: 0:27:28.930592 | Iteration:  1600 | Batch:  266/667 | Train loss: 0.6933 | Val loss: 0.6924\n",
      "   % Time: 0:29:12.092595 | Iteration:  1700 | Batch:  366/667 | Train loss: 0.6929 | Val loss: 0.6920\n",
      "   % Time: 0:30:54.998296 | Iteration:  1800 | Batch:  466/667 | Train loss: 0.6929 | Val loss: 0.6927\n",
      "   % Time: 0:32:37.740151 | Iteration:  1900 | Batch:  566/667 | Train loss: 0.6920 | Val loss: 0.6929\n",
      "   % Time: 0:34:20.795365 | Iteration:  2000 | Batch:  666/667 | Train loss: 0.6926 | Val loss: 0.6918\n",
      "\n",
      "=> EPOCH 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb74773c94948dbbb36404b452b003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:36:03.499585 | Iteration:  2100 | Batch:   99/667 | Train loss: 0.6932 | Val loss: 0.6923\n",
      "   % Time: 0:37:46.510389 | Iteration:  2200 | Batch:  199/667 | Train loss: 0.6927 | Val loss: 0.6942\n",
      "   % Time: 0:39:29.271913 | Iteration:  2300 | Batch:  299/667 | Train loss: 0.6926 | Val loss: 0.6916\n",
      "   % Time: 0:41:12.422652 | Iteration:  2400 | Batch:  399/667 | Train loss: 0.6917 | Val loss: 0.6916\n",
      "   % Time: 0:42:55.318922 | Iteration:  2500 | Batch:  499/667 | Train loss: 0.6925 | Val loss: 0.6914\n",
      "   % Time: 0:44:38.159164 | Iteration:  2600 | Batch:  599/667 | Train loss: 0.6925 | Val loss: 0.6919\n",
      "\n",
      "=> EPOCH 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6945208b47404fdba1436b9863a54322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:46:20.764817 | Iteration:  2700 | Batch:   32/667 | Train loss: 0.6918 | Val loss: 0.6915\n",
      "   % Time: 0:48:03.926512 | Iteration:  2800 | Batch:  132/667 | Train loss: 0.6918 | Val loss: 0.6919\n",
      "   % Time: 0:49:46.724723 | Iteration:  2900 | Batch:  232/667 | Train loss: 0.6924 | Val loss: 0.6915\n",
      "   % Time: 0:51:29.475810 | Iteration:  3000 | Batch:  332/667 | Train loss: 0.6918 | Val loss: 0.6916\n",
      "   % Time: 0:53:12.400121 | Iteration:  3100 | Batch:  432/667 | Train loss: 0.6931 | Val loss: 0.6916\n",
      "   % Time: 0:54:55.354984 | Iteration:  3200 | Batch:  532/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 0:56:39.002330 | Iteration:  3300 | Batch:  632/667 | Train loss: 0.6928 | Val loss: 0.6916\n",
      "\n",
      "=> EPOCH 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b480b7cd31a441880f2149243d77fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:58:21.822922 | Iteration:  3400 | Batch:   65/667 | Train loss: 0.6919 | Val loss: 0.6917\n",
      "   % Time: 1:00:04.773279 | Iteration:  3500 | Batch:  165/667 | Train loss: 0.6921 | Val loss: 0.6914\n",
      "   % Time: 1:01:47.408068 | Iteration:  3600 | Batch:  265/667 | Train loss: 0.6918 | Val loss: 0.6913\n",
      "   % Time: 1:03:30.645946 | Iteration:  3700 | Batch:  365/667 | Train loss: 0.6919 | Val loss: 0.6915\n",
      "   % Time: 1:05:14.800460 | Iteration:  3800 | Batch:  465/667 | Train loss: 0.6916 | Val loss: 0.6911\n",
      "   % Time: 1:06:58.463083 | Iteration:  3900 | Batch:  565/667 | Train loss: 0.6919 | Val loss: 0.6916\n",
      "   % Time: 1:08:41.594795 | Iteration:  4000 | Batch:  665/667 | Train loss: 0.6929 | Val loss: 0.6913\n",
      "\n",
      "=> EPOCH 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893e08e3e4bc4716b7054915fa0acfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:10:24.484646 | Iteration:  4100 | Batch:   98/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 1:12:07.046520 | Iteration:  4200 | Batch:  198/667 | Train loss: 0.6919 | Val loss: 0.6914\n",
      "   % Time: 1:13:49.616556 | Iteration:  4300 | Batch:  298/667 | Train loss: 0.6917 | Val loss: 0.6912\n",
      "   % Time: 1:15:32.444589 | Iteration:  4400 | Batch:  398/667 | Train loss: 0.6913 | Val loss: 0.6908\n",
      "   % Time: 1:17:15.573810 | Iteration:  4500 | Batch:  498/667 | Train loss: 0.6914 | Val loss: 0.6909\n",
      "   % Time: 1:18:58.556091 | Iteration:  4600 | Batch:  598/667 | Train loss: 0.6912 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788b04bd80d41d28bdd711d0b3bf7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:20:41.073296 | Iteration:  4700 | Batch:   31/667 | Train loss: 0.6920 | Val loss: 0.6909\n",
      "   % Time: 1:22:23.977725 | Iteration:  4800 | Batch:  131/667 | Train loss: 0.6911 | Val loss: 0.6912\n",
      "   % Time: 1:24:06.920420 | Iteration:  4900 | Batch:  231/667 | Train loss: 0.6903 | Val loss: 0.6909\n",
      "   % Time: 1:25:49.773948 | Iteration:  5000 | Batch:  331/667 | Train loss: 0.6910 | Val loss: 0.6914\n",
      "   % Time: 1:27:32.880611 | Iteration:  5100 | Batch:  431/667 | Train loss: 0.6911 | Val loss: 0.6917\n",
      "   % Time: 1:29:16.246776 | Iteration:  5200 | Batch:  531/667 | Train loss: 0.6906 | Val loss: 0.6913\n",
      "   % Time: 1:30:59.080945 | Iteration:  5300 | Batch:  631/667 | Train loss: 0.6915 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478364f5fe384952a127c3ef0db17e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:32:41.803908 | Iteration:  5400 | Batch:   64/667 | Train loss: 0.6911 | Val loss: 0.6914\n",
      "=> Adjust learning rate to: 0.006999999999999999\n",
      "   % Time: 1:34:24.458104 | Iteration:  5500 | Batch:  164/667 | Train loss: 0.6895 | Val loss: 0.6916\n",
      "   % Time: 1:36:07.163432 | Iteration:  5600 | Batch:  264/667 | Train loss: 0.6908 | Val loss: 0.6913\n",
      "   % Time: 1:37:50.319805 | Iteration:  5700 | Batch:  364/667 | Train loss: 0.6914 | Val loss: 0.6912\n",
      "   % Time: 1:39:33.526270 | Iteration:  5800 | Batch:  464/667 | Train loss: 0.6895 | Val loss: 0.6910\n",
      "   % Time: 1:41:16.676685 | Iteration:  5900 | Batch:  564/667 | Train loss: 0.6906 | Val loss: 0.6911\n",
      "   % Time: 1:42:59.682476 | Iteration:  6000 | Batch:  664/667 | Train loss: 0.6901 | Val loss: 0.6910\n",
      "\n",
      "=> EPOCH 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bae6ee69d114834a5c8c7602c9ba8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:44:42.483787 | Iteration:  6100 | Batch:   97/667 | Train loss: 0.6890 | Val loss: 0.6912\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-77791d40d758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \"w+\")\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5416212a9406>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> EPOCH {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# total iteration within all batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5687f46f2bd9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOKENS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/cathay/src/preprocessing/feature_engineering/bert_embedding.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, row_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                           \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                           \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                           \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                                          )\n\u001b[1;32m     33\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# however, we do not take cls & \\cls into consideration when building the embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id_with_added_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# saved = True\n",
    "# if 1 == 1:  # change to True to train\n",
    "#     iteration = n_total = train_loss = n_bad_loss = 0\n",
    "#     stop = False\n",
    "#     best_val_loss = float(\"inf\")\n",
    "#     init = datetime.now()\n",
    "#     config.epochs = 10\n",
    "# #     config.n_bad_loss 4\n",
    "#     if saved:\n",
    "#         write_log(\"Start record at {}\\n\".format(str(datetime.now())),\n",
    "#                   config.log_file,\n",
    "#                   \"w+\")\n",
    "#     for epoch in range(1, config.epochs+1):\n",
    "#         train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "#         if stop:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:10.966688Z",
     "start_time": "2020-08-05T07:27:10.964582Z"
    }
   },
   "source": [
    "## 8. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_name = config.best_model.split(\"/\")[-1][:-4] # default\n",
    "result_name = \"\"\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(result_name))\n",
    "config.log_file = os.path.join(config.log_path, \"{}.txt\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_load(config, \n",
    "                        BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device),\n",
    "                        name=result_name,\n",
    "                       )\n",
    "y_true, y_pred, y_prob = test(config, test_loader, model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.10      0.18     21307\n",
      "         1.0       0.51      0.93      0.66     21336\n",
      "\n",
      "    accuracy                           0.52     42643\n",
      "   macro avg       0.56      0.52      0.42     42643\n",
      "weighted avg       0.56      0.52      0.42     42643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# write the report\n",
    "write_log(\"\\n{}\\n\\n{}\\n\".\\\n",
    "          format(\"=== Classification Report ===\",\n",
    "                 report\n",
    "                ),\n",
    "          config.log_file,\n",
    "          \"a+\")\n",
    "\n",
    "# print\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. Saving Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.PREDICTED_RESULT = os.path.join(\"result/graph/prediction\", \"{}.pkl\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predicted result\n",
    "with open(config.PREDICTED_RESULT, 'wb') as f:\n",
    "    pickle.dump([y_true, y_pred, y_prob], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.PREDICTED_RESULT, 'rb') as f:\n",
    "    y_true, y_pred, y_prob = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.log_file, \"r+\") as file:\n",
    "    logs = file.readlines()\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    for row in logs:\n",
    "        if len(row.split(\"|\")) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            train_loss.append(float(row.split(\"|\")[-2].strip().split(\" \")[-1]))\n",
    "            val_loss.append(float(row.split(\"|\")[-1].strip().split(\" \")[-1]))\n",
    "    assert len(train_loss) == len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(train_loss)), train_loss, '-b', label='train')\n",
    "ax.plot(range(len(val_loss)), val_loss, '--r', label='validation')\n",
    "leg = ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
