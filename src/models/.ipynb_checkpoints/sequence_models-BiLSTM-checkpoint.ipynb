{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:23.407418Z",
     "start_time": "2020-08-05T07:13:23.398377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /scratch/kll482/cathay\n",
      "Config Sections: ['text_cleaning', 'feature_engineering', 'graph_models']\n"
     ]
    }
   ],
   "source": [
    "''' root '''\n",
    "import os\n",
    "os.chdir(\"/scratch/kll482/cathay\")\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/scratch/kll482/cathay/\")\n",
    "\n",
    "''' config '''\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read(\"config/config.ini\")\n",
    "print(\"Config Sections:\", config.sections())\n",
    "args = config[\"graph_models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:15:33.614186Z",
     "start_time": "2020-08-05T07:15:33.609071Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' packages '''\n",
    "# import torch, torchvision\n",
    "# import pandas as pd, numpy as np\n",
    "# import argparse\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# # from torch_geometric.data.InMemoryDataset import collate\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' packages '''\n",
    "# 1. models\n",
    "import torch, torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 2. others\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import pandas as pd, numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter(\"logs/graph/\")\n",
    "\n",
    "# 3. custom\n",
    "from src.preprocessing.feature_engineering.bert_embedding import BertEmbedding\n",
    "from src.utils.vocabulary import Vocabulary\n",
    "from src.utils.pipeline import Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initial Variables & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:28.592867Z",
     "start_time": "2020-08-05T07:13:28.589113Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Hyperparameters '''\n",
    "parser = {\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 5, # random seed\n",
    "    \"epochs\": 5,\n",
    "    \"cuda\": True, # use cuda or not\n",
    "    \"log_every\": 100,\n",
    "    \"lr\": 0.01,  # initial learning rate\n",
    "    \"lr_decay\": 0.7,  # decay lr when not observing improvement in val_loss\n",
    "    \"lr_min\": 1e-5,  # stop when lr is too low\n",
    "    \"n_bad_loss\": 4,  # number of bad val_loss before decaying\n",
    "    \"clip\": 2.3,\n",
    "    \"result_path\": \"result/sequence/\",  # path to save models\n",
    "    \"log_path\": \"logs/sequence/\",\n",
    "}\n",
    "config = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' General '''\n",
    "config.USE_CUDA = 1 # bool(int(args[\"use_cuda\"]))\n",
    "config.SEED = int(args[\"set_seed\"])\n",
    "config.MODELING_FEATURE_PATH = args[\"modeling_feature_path\"]\n",
    "config.DATA_PATH = args[\"data_path\"]\n",
    "config.NUM_FEATURES = 768\n",
    "config.N_CLASSES = 1\n",
    "config.TARGET = \"overall\"\n",
    "config.TOKENS = \"reviewTokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. CUDA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.284510Z",
     "start_time": "2020-08-05T07:13:29.276557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda on:  True\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config.USE_CUDA = config.USE_CUDA and torch.cuda.is_available()\n",
    "print(\"cuda on: \", config.USE_CUDA)\n",
    "if config.USE_CUDA:\n",
    "    torch.cuda.manual_seed(config.SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    torch.manual_seed(config.SEED)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if config.USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:13:29.480321Z",
     "start_time": "2020-08-05T07:13:29.476385Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=config.SEED):\n",
    "    #random.seed(seed)\n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:14:27.559723Z",
     "start_time": "2020-08-05T07:13:30.485201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the datasets...\n"
     ]
    }
   ],
   "source": [
    "print(\"read the datasets...\")\n",
    "files = []\n",
    "# file_path = [file for file in os.listdir(config.DATA_PATH) if file.endswith(\".json\")]\n",
    "file_path = ['Video_Games_5.json', 'Musical_Instruments_5.json']\n",
    "for file in file_path:    \n",
    "    files.append(pd.read_json(os.path.join(config.DATA_PATH, file)))\n",
    "    \n",
    "df = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727329, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTokens</th>\n",
       "      <th>uniqueTokens</th>\n",
       "      <th>edgeIndex3</th>\n",
       "      <th>edgeIndex5</th>\n",
       "      <th>edgeIndex10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
       "      <td>[game, bit, hard, get, hang, great]</td>\n",
       "      <td>[great, get, hard, game, hang, bit]</td>\n",
       "      <td>[[3, 5, 3, 2, 3, 1, 5, 3, 5, 2, 5, 1, 5, 4, 2,...</td>\n",
       "      <td>[[3, 5, 3, 2, 3, 1, 3, 4, 3, 0, 5, 3, 5, 2, 5,...</td>\n",
       "      <td>[[3, 5, 3, 2, 3, 1, 3, 4, 3, 0, 5, 3, 5, 2, 5,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "      <td>[play, alright, steam, bit, trouble, move, gam...</td>\n",
       "      <td>[way, hard, activate, anno, alright, fun, game...</td>\n",
       "      <td>[[18, 4, 18, 11, 18, 12, 4, 18, 4, 11, 4, 12, ...</td>\n",
       "      <td>[[18, 4, 18, 11, 18, 12, 18, 15, 18, 14, 4, 18...</td>\n",
       "      <td>[[18, 4, 18, 11, 18, 12, 18, 15, 18, 14, 18, 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ok game.</td>\n",
       "      <td>[ok, game]</td>\n",
       "      <td>[ok, game]</td>\n",
       "      <td>[[0, 1, 1, 0], [1, 0, 0, 1]]</td>\n",
       "      <td>[[0, 1, 1, 0], [1, 0, 0, 1]]</td>\n",
       "      <td>[[0, 1, 1, 0], [1, 0, 0, 1]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0        5  This game is a bit hard to get the hang of, bu...   \n",
       "1        4  I played it a while but it was alright. The st...   \n",
       "2        3                                           ok game.   \n",
       "\n",
       "                                        reviewTokens  \\\n",
       "0                [game, bit, hard, get, hang, great]   \n",
       "1  [play, alright, steam, bit, trouble, move, gam...   \n",
       "2                                         [ok, game]   \n",
       "\n",
       "                                        uniqueTokens  \\\n",
       "0                [great, get, hard, game, hang, bit]   \n",
       "1  [way, hard, activate, anno, alright, fun, game...   \n",
       "2                                         [ok, game]   \n",
       "\n",
       "                                          edgeIndex3  \\\n",
       "0  [[3, 5, 3, 2, 3, 1, 5, 3, 5, 2, 5, 1, 5, 4, 2,...   \n",
       "1  [[18, 4, 18, 11, 18, 12, 4, 18, 4, 11, 4, 12, ...   \n",
       "2                       [[0, 1, 1, 0], [1, 0, 0, 1]]   \n",
       "\n",
       "                                          edgeIndex5  \\\n",
       "0  [[3, 5, 3, 2, 3, 1, 3, 4, 3, 0, 5, 3, 5, 2, 5,...   \n",
       "1  [[18, 4, 18, 11, 18, 12, 18, 15, 18, 14, 4, 18...   \n",
       "2                       [[0, 1, 1, 0], [1, 0, 0, 1]]   \n",
       "\n",
       "                                         edgeIndex10  y  \n",
       "0  [[3, 5, 3, 2, 3, 1, 3, 4, 3, 0, 5, 3, 5, 2, 5,...  1  \n",
       "1  [[18, 4, 18, 11, 18, 12, 18, 15, 18, 14, 18, 6...  1  \n",
       "2                       [[0, 1, 1, 0], [1, 0, 0, 1]]  1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the length of review tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 3075\n",
      "min: 1\n",
      "median: 18.0\n",
      "mean: 52.301840020128445\n",
      "Q3: 52.0\n",
      "Q1: 6.0\n",
      "Q(90%): 134.0\n"
     ]
    }
   ],
   "source": [
    "review_len = [len(row) for row in df[\"reviewTokens\"]]\n",
    "print(\"max:\", max(review_len))\n",
    "print(\"min:\", min(review_len))\n",
    "print(\"median:\", np.median(review_len))\n",
    "print(\"mean:\", np.mean(review_len))\n",
    "print(\"Q3:\", np.quantile(review_len, 0.75))\n",
    "print(\"Q1:\", np.quantile(review_len, 0.25))\n",
    "print(\"Q(90%):\", np.quantile(review_len, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_len = [len(row) for row in df[\"uniqueTokens\"]]\n",
    "sns.distplot(word_len, hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Review Score to Positive/Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify(df, target=\"overall\"):\n",
    "    '''\n",
    "    1. score 3 & 4 & 5 -> 1 (positive)\n",
    "    2. score 1 & 2 -> 0 (negative)\n",
    "    '''\n",
    "    y = []\n",
    "    for gp in df[target]:\n",
    "        if gp in [3, 4, 5]:\n",
    "            y.append(1)\n",
    "        elif gp in [1, 2]:\n",
    "            y.append(0)\n",
    "    assert len(y) == df.shape[0]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = reclassify(df, \"overall\")\n",
    "config.TARGET = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(df, train_percent=0.8, val_percent=0.1, set_seed=config.SEED):\n",
    "    n = df.shape[0] # get length of dataframe\n",
    "\n",
    "    # I will set the percentage of validation and test sets to be both 0.1\n",
    "    train_index, rest_index = train_test_split(range(n), train_size=0.8, random_state=config.SEED)\n",
    "    val_index, test_index = train_test_split(rest_index, train_size=(val_percent/(1-train_percent)), random_state=config.SEED) # 0.1/(1-0.8) = 0.1/0.2 = 0.5\n",
    "\n",
    "    # check if there is any intersection among all three sets\n",
    "    assert len(set(train_index + val_index + test_index)) == n\n",
    "\n",
    "    # get sub_datasets by random_split\n",
    "    np.random.seed(config.SEED)\n",
    "    train_df, val_df, test_df = df.iloc[train_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[val_index, :].reset_index(drop=True),\\\n",
    "                                df.iloc[test_index, :].reset_index(drop=True)\n",
    "\n",
    "    # check random_split works correctly\n",
    "    assert (len(train_df)+len(val_df)+len(test_df)) == n\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = dataset_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Build Vocabulary\n",
    "\n",
    "It's reasonable to build a vocabulary list from only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "\n",
    "for row in train_df[config.TOKENS]:\n",
    "    for word in row:\n",
    "        vocabulary.add_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. Imbalanced Dataset\n",
    "\n",
    "Note: I only make the training set balanced and leave the validation and test sets alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='y', ylabel='count'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the imbalanced target variable\n",
    "sns.countplot(train_df[config.TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "def undersampling(df, target=config.TARGET, set_seed=config.SEED):\n",
    "    np.random.seed(set_seed)\n",
    "    df = df.groupby(target)\n",
    "    df = df.apply(lambda x: x.sample(df.size().min())).sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 111520\n",
      "Length of test set: 72733\n"
     ]
    }
   ],
   "source": [
    "train_df = undersampling(train_df)\n",
    "print(\"Length of training set:\", train_df.shape[0])\n",
    "print(\"Length of test set:\", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, config, df, use_cuda, embeddings):\n",
    "        self.df = df\n",
    "        self.use_cuda = use_cuda\n",
    "        self.embeddings = embeddings\n",
    "        self.config = config\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tt = torch.cuda if self.use_cuda else torch\n",
    "        x = tt.FloatTensor(self.embeddings.get_embeddings(self.df[self.config.TOKENS][idx]))\n",
    "#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\n",
    "        y = tt.FloatTensor([self.df[self.config.TARGET][idx]])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the row length remains the same even we transform dataframe into graph dataset\n",
    "assert len(train_dataset)+len(val_dataset)+len(test_dataset) == len(train_df)+len(val_df)+len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T01:24:33.012811Z",
     "start_time": "2020-08-05T01:24:33.006012Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' For InMemoryDataset '''\n",
    "# def get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1):\n",
    "    \n",
    "#     # get length of subsets\n",
    "#     train_len = int(dataset.__len__()*0.8)\n",
    "#     val_len = int(dataset.__len__()*0.1)\n",
    "#     test_len = dataset.__len__()-train_len-val_len\n",
    "    \n",
    "#     # get sub_datasets by random_split\n",
    "#     seed_torch(config.SEED)\n",
    "#     train_dataset, val_dataset, test_dataset = random_split(dataset, (train_len, val_len, test_len))\n",
    "    \n",
    "#     # check random_split works correctly\n",
    "#     assert (len(train_dataset)+len(val_dataset)+len(test_dataset)) == dataset.__len__()\n",
    "    \n",
    "#     # get dataloaders\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "#     test_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "#     return train_loader, val_loader, test_loader\n",
    "\n",
    "# train_loader, val_loader, test_loader = get_dataloaders(config, dataset, train_percent=0.8, val_percent=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch(config.SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class MultiClassBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, lstm_layer=2, dropout=0.3):\n",
    "        super(MultiClassBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = torch.transpose(x, dim0=1, dim1=0)\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: batch, num_seq, 2*hidden\n",
    "        out = self.relu(out)\n",
    "        print(out.size())\n",
    "        out = self.classify(out)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "class BinaryBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_classes=1, lstm_layer=2, dropout=0.3, hidden_transfer=\"last\"):\n",
    "        super(BinaryBiLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=embedding_dim,\n",
    "                            num_layers=lstm_layer, \n",
    "                            dropout = dropout,\n",
    "                            bidirectional=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classify = nn.Linear(embedding_dim*2, n_classes)\n",
    "        \n",
    "        assert hidden_transfer in [\"mean\", \"last\"]\n",
    "        self.hidden_transfer = hidden_transfer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, dim0=1, dim1=0) # x: batch x seq_len x embedding_dim -> seq_len x batch x embedding_dim\n",
    "        out, (h_n, c_n) = self.lstm(x) # out: seq_len x batch x 2*embedding_dim\n",
    "        if self.hidden_transfer == \"mean\":\n",
    "            out = torch.mean(out, dim=0)\n",
    "        elif self.hidden_transfer == \"last\":\n",
    "            out = out[-1] # out: batch x 2*embedding_dim\n",
    "        out = self.relu(out) # out: batch x 2*embedding_dim\n",
    "        out = self.classify(out) # out: batch x n_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train & Validation & Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:34:54.271139Z",
     "start_time": "2020-08-05T06:34:54.268293Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(text, file_path, mode=\"a+\"):\n",
    "    print(text)\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(config):\n",
    "    texts = \"=== Settings ===\\n\"\n",
    "    var_config = vars(config)\n",
    "    for i in range(len(var_config)):\n",
    "        temp_text = \"{}: {}\\n\".format(list(var_config.keys())[i],\n",
    "                                      list(var_config.values())[i],\n",
    "                                     )\n",
    "        texts += temp_text\n",
    "    texts += \"============\\n\\n\"\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.217809Z",
     "start_time": "2020-08-05T06:49:58.207574Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config, train_loader, val_loader, model, criterion, optimizer):\n",
    "    global iteration, n_total, train_loss, n_bad_loss\n",
    "    global init, best_val_loss, stop\n",
    "\n",
    "    logs = \"=> EPOCH {}\".format(epoch)\n",
    "    write_log(logs, config.log_file, \"a+\")\n",
    "    \n",
    "    for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "        iteration += 1 # total iteration within all batches\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        \n",
    "        # train the model\n",
    "        model.train()\n",
    "#         for param in model.parameters():\n",
    "#             print(param.requires_grad)\n",
    "        output = model(batch[0])\n",
    "        \n",
    "        # loss function\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        # BP\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        # sum with the previous training loss for updating learning rate in the following\n",
    "        train_loss += batch_size * loss.item() # accumulated training loss; batch.num_graphs is the size of the batch\n",
    "        n_total += batch_size\n",
    "        \n",
    "#         # validation check\n",
    "        if iteration % config.log_every == 0:\n",
    "            train_loss /= n_total \n",
    "            val_loss = validate(config, val_loader, model, criterion)\n",
    "        \n",
    "            # save logs\n",
    "            logs = \"   % Time: {} | Iteration: {:5} | Batch: {:4}/{}\"\\\n",
    "                  \" | Train loss: {:.4f} | Val loss: {:.4f}\"\\\n",
    "                  .format(str(datetime.now()-init), iteration, batch_index+1,\n",
    "                          len(train_loader), train_loss, val_loss)\n",
    "            write_log(logs, config.log_file, \"a+\")\n",
    "\n",
    "            # test for val_loss improvement\n",
    "            n_total = train_loss = 0\n",
    "            if val_loss < best_val_loss: # update the best validation loss\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                torch.save(model.state_dict(), config.best_model) # save the checkpoint\n",
    "            else:\n",
    "                n_bad_loss += 1\n",
    "            \n",
    "            # update the learning rate if val loss does not improve for n_bad_loss times\n",
    "            if n_bad_loss == config.n_bad_loss:\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                adjust_learning_rate(optimizer, config.lr_decay)\n",
    "                new_lr = optimizer.param_groups[0]['lr']\n",
    "                \n",
    "                logs = \"=> Adjust learning rate to: {}\".format(new_lr)\n",
    "                write_log(logs, config.log_file, \"a+\")\n",
    "                \n",
    "                if new_lr < config.lr_min:\n",
    "                    stop = True\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T06:49:58.794219Z",
     "start_time": "2020-08-05T06:49:58.789194Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(config, val_loader, model, criterion):\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    dataset_size = 0\n",
    "    for batch in val_loader:\n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        if config.N_CLASSES == 1:\n",
    "            # binary\n",
    "            label = batch[1].float()\n",
    "        elif config.N_CLASSES > 1:\n",
    "            label = batch[1].long()\n",
    "        label = label.to(device).detach()\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        # train the model\n",
    "        output = model(batch[0])\n",
    "        loss = criterion(output, label)\n",
    "        val_loss += loss.data * batch_size\n",
    "    return val_loss / dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:08.304060Z",
     "start_time": "2020-08-05T07:27:08.298175Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(config, test_loader, model, threshold=0.5):\n",
    "    print(\"start testing...\")\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    label_list = []\n",
    "    prediction_list = []\n",
    "        \n",
    "    if config.N_CLASSES > 1:\n",
    "        for batch in tqdm(test_loader):\n",
    "            # binary\n",
    "            label = batch[1].long()\n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            \n",
    "            output = model(batch[0])\n",
    "            _, prediction = torch.max(output, 1)\n",
    "            prediction = prediction.data.tolist()\n",
    "            prediction_list += prediction\n",
    "            \n",
    "    elif config.N_CLASSES == 1:\n",
    "        for batch in tqdm(test_loader):\n",
    "            label = batch[1].float()            \n",
    "            label = label.data.tolist()\n",
    "            label_list += label\n",
    "            \n",
    "            output = model(batch[0]).squeeze(-1)\n",
    "            sigmoid = nn.Sigmoid() \n",
    "            output = sigmoid(output) # [-inf, inf] -> [0, 1]\n",
    "            prediction_list += [1 if output > threshold else 0]\n",
    "   \n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(label_list, prediction_list))#.rename(columns=[\"1\",\"2\",\"3\",\"4\",\"5\"], index=[\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    print(confusion_matrix_df)\n",
    "    sns.heatmap(confusion_matrix_df, annot=True)\n",
    "    \n",
    "    return label_list, prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(config, model_test, name):\n",
    "    if name is None:\n",
    "        model_reloaded = config.best_model\n",
    "    else:\n",
    "        model_reloaded = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(name))\n",
    "    model_train = torch.load(model_reloaded)\n",
    "#     model_test = BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    model_test.load_state_dict(model_train)\n",
    "\n",
    "    return model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "batch_size: 64\n",
      "seed: 5\n",
      "epochs: 15\n",
      "cuda: True\n",
      "log_every: 500\n",
      "lr: 0.001\n",
      "lr_decay: 0.7\n",
      "lr_min: 1e-05\n",
      "n_bad_loss: 4\n",
      "clip: 2.3\n",
      "result_path: result/sequence/\n",
      "log_path: logs/sequence/\n",
      "USE_CUDA: True\n",
      "SEED: 123\n",
      "MODELING_FEATURE_PATH: dataset/full_dataset/modeling_features.json\n",
      "DATA_PATH: dataset/processed_dataset/\n",
      "NUM_FEATURES: 768\n",
      "N_CLASSES: 1\n",
      "TARGET: y\n",
      "TOKENS: reviewTokens\n",
      "best_model: result/sequence/checkpoint/BiLSTM_2020_08_24_04_40.pth\n",
      "log_file: logs/sequence/BiLSTM_2020_08_24_04_40.txt\n",
      "============\n",
      "\n",
      "Start record at 2020-08-24 04:40:50.345092\n",
      "\n",
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b99fff789542d4b437228b9177e1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:09:37.781457 | Iteration:   500 | Batch:  500/1743 | Train loss: 0.6779 | Val loss: 0.5929\n",
      "   % Time: 0:19:17.214254 | Iteration:  1000 | Batch: 1000/1743 | Train loss: 0.6868 | Val loss: 0.6600\n",
      "   % Time: 0:28:54.600647 | Iteration:  1500 | Batch: 1500/1743 | Train loss: 0.6853 | Val loss: 0.6587\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d395431d78409f8dded44ee5c301e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:38:33.100316 | Iteration:  2000 | Batch:  257/1743 | Train loss: 0.6801 | Val loss: 0.7040\n",
      "   % Time: 0:48:12.901609 | Iteration:  2500 | Batch:  757/1743 | Train loss: 0.6731 | Val loss: 0.6978\n",
      "=> Adjust learning rate to: 0.0007\n",
      "   % Time: 0:57:53.096547 | Iteration:  3000 | Batch: 1257/1743 | Train loss: 0.6842 | Val loss: 0.6475\n",
      "\n",
      "=> EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f59913c64848bdbf519a5e77ce7e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:07:30.810014 | Iteration:  3500 | Batch:   14/1743 | Train loss: 0.6783 | Val loss: 0.6813\n"
     ]
    }
   ],
   "source": [
    "''' initials '''\n",
    "# seed_torch(config.SEED)\n",
    "seed_torch(config.SEED)\n",
    "config.N_CLASSES = 1\n",
    "model_name = \"BiLSTM\"\n",
    "\n",
    "''' rebuild dataset and dataloader due to edge_index '''\n",
    "train_dataset = ReviewDataset(config,\n",
    "                       df=train_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )\n",
    "val_dataset = ReviewDataset(config,\n",
    "                       df=val_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )\n",
    "test_dataset = ReviewDataset(config,\n",
    "                       df=test_df,\n",
    "                       use_cuda=config.USE_CUDA,\n",
    "                       embeddings=BertEmbedding(max_len=58),\n",
    "                       )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "''' initializing the model '''\n",
    "if config.N_CLASSES == 1:\n",
    "    # binary\n",
    "    model = BinaryBiLSTM(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "else:\n",
    "    # MultiClass\n",
    "    model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "                             n_classes=config.N_CLASSES,\n",
    "                             dropout=0).to(device)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}_{}.pth\".format(model_name,\n",
    "                                                                                   datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                                  )\n",
    "                                )\n",
    "config.log_file = os.path.join(config.log_path, \"{}_{}.txt\".format(model_name,\n",
    "                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "                                                                            )\n",
    "                              )\n",
    "''' start training '''\n",
    "saved = True\n",
    "if 1 == 1:  # change to True to train\n",
    "    iteration = n_total = train_loss = n_bad_loss = 0\n",
    "    stop = False\n",
    "    best_val_loss = float(\"inf\")\n",
    "    init = datetime.now()\n",
    "    config.epochs = 15\n",
    "    config.log_every = 500\n",
    "    config.lr = 0.001\n",
    "    config.n_bad_loss = 4\n",
    "\n",
    "    if saved:\n",
    "        output_text = write_config(config) + \"Start record at {}\\n\".format(str(datetime.now()))\n",
    "        write_log(output_text,\n",
    "                  config.log_file,\n",
    "                  \"w+\")\n",
    "        \n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_torch(config.SEED)\n",
    "# config.N_CLASSES = 1\n",
    "\n",
    "# if config.N_CLASSES == 1:\n",
    "#     # binary\n",
    "#     model = BinaryBiLSTM(config.NUM_FEATURES, config.N_CLASSES).to(device)\n",
    "#     criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# else:\n",
    "#     # MultiClass\n",
    "#     model = MultiClassBiLSTM(embedding_dim=config.NUM_FEATURES,\n",
    "#                              n_classes=config.N_CLASSES,\n",
    "#                              dropout=0).to(device)\n",
    "#     criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=config.lr)\n",
    "\n",
    "# config.best_model = os.path.join(config.result_path, \"checkpoint/neighbor{}_{}_{}.pth\".format(3,\n",
    "#                                                                                              \"LSTM\",\n",
    "#                                                                                              datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                             )\n",
    "#                                 )\n",
    "# config.log_file = os.path.join(config.log_path, \"neighbor{}_{}_{}.txt\".format(3,\n",
    "#                                                                               \"LSTM\",\n",
    "#                                                                               datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "#                                                                                )\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:22:47.974384Z",
     "start_time": "2020-08-05T07:22:47.972571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79615820f5724ce59dbeca8ba2ffe611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:01:46.178220 | Iteration:   100 | Batch:  100/667 | Train loss: 0.7400 | Val loss: 0.6931\n",
      "   % Time: 0:03:29.330737 | Iteration:   200 | Batch:  200/667 | Train loss: 0.6942 | Val loss: 0.6950\n",
      "   % Time: 0:05:12.249364 | Iteration:   300 | Batch:  300/667 | Train loss: 0.6939 | Val loss: 0.6931\n",
      "   % Time: 0:06:55.106757 | Iteration:   400 | Batch:  400/667 | Train loss: 0.6938 | Val loss: 0.6932\n",
      "   % Time: 0:08:37.712439 | Iteration:   500 | Batch:  500/667 | Train loss: 0.6938 | Val loss: 0.6944\n",
      "   % Time: 0:10:20.419047 | Iteration:   600 | Batch:  600/667 | Train loss: 0.6936 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d0af5c1b0749ffaedcd8cf1b569ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:12:03.191009 | Iteration:   700 | Batch:   33/667 | Train loss: 0.6935 | Val loss: 0.6929\n",
      "   % Time: 0:13:46.022992 | Iteration:   800 | Batch:  133/667 | Train loss: 0.6932 | Val loss: 0.6945\n",
      "   % Time: 0:15:28.779864 | Iteration:   900 | Batch:  233/667 | Train loss: 0.6936 | Val loss: 0.6940\n",
      "   % Time: 0:17:11.843233 | Iteration:  1000 | Batch:  333/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:18:54.798077 | Iteration:  1100 | Batch:  433/667 | Train loss: 0.6932 | Val loss: 0.6928\n",
      "   % Time: 0:20:37.708624 | Iteration:  1200 | Batch:  533/667 | Train loss: 0.6931 | Val loss: 0.6925\n",
      "   % Time: 0:22:20.965800 | Iteration:  1300 | Batch:  633/667 | Train loss: 0.6931 | Val loss: 0.6930\n",
      "\n",
      "=> EPOCH 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64836e8c9e204fce9fb82f97a2e9e9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:24:03.325921 | Iteration:  1400 | Batch:   66/667 | Train loss: 0.6933 | Val loss: 0.6925\n",
      "   % Time: 0:25:46.083991 | Iteration:  1500 | Batch:  166/667 | Train loss: 0.6928 | Val loss: 0.6926\n",
      "   % Time: 0:27:28.930592 | Iteration:  1600 | Batch:  266/667 | Train loss: 0.6933 | Val loss: 0.6924\n",
      "   % Time: 0:29:12.092595 | Iteration:  1700 | Batch:  366/667 | Train loss: 0.6929 | Val loss: 0.6920\n",
      "   % Time: 0:30:54.998296 | Iteration:  1800 | Batch:  466/667 | Train loss: 0.6929 | Val loss: 0.6927\n",
      "   % Time: 0:32:37.740151 | Iteration:  1900 | Batch:  566/667 | Train loss: 0.6920 | Val loss: 0.6929\n",
      "   % Time: 0:34:20.795365 | Iteration:  2000 | Batch:  666/667 | Train loss: 0.6926 | Val loss: 0.6918\n",
      "\n",
      "=> EPOCH 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb74773c94948dbbb36404b452b003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:36:03.499585 | Iteration:  2100 | Batch:   99/667 | Train loss: 0.6932 | Val loss: 0.6923\n",
      "   % Time: 0:37:46.510389 | Iteration:  2200 | Batch:  199/667 | Train loss: 0.6927 | Val loss: 0.6942\n",
      "   % Time: 0:39:29.271913 | Iteration:  2300 | Batch:  299/667 | Train loss: 0.6926 | Val loss: 0.6916\n",
      "   % Time: 0:41:12.422652 | Iteration:  2400 | Batch:  399/667 | Train loss: 0.6917 | Val loss: 0.6916\n",
      "   % Time: 0:42:55.318922 | Iteration:  2500 | Batch:  499/667 | Train loss: 0.6925 | Val loss: 0.6914\n",
      "   % Time: 0:44:38.159164 | Iteration:  2600 | Batch:  599/667 | Train loss: 0.6925 | Val loss: 0.6919\n",
      "\n",
      "=> EPOCH 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6945208b47404fdba1436b9863a54322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:46:20.764817 | Iteration:  2700 | Batch:   32/667 | Train loss: 0.6918 | Val loss: 0.6915\n",
      "   % Time: 0:48:03.926512 | Iteration:  2800 | Batch:  132/667 | Train loss: 0.6918 | Val loss: 0.6919\n",
      "   % Time: 0:49:46.724723 | Iteration:  2900 | Batch:  232/667 | Train loss: 0.6924 | Val loss: 0.6915\n",
      "   % Time: 0:51:29.475810 | Iteration:  3000 | Batch:  332/667 | Train loss: 0.6918 | Val loss: 0.6916\n",
      "   % Time: 0:53:12.400121 | Iteration:  3100 | Batch:  432/667 | Train loss: 0.6931 | Val loss: 0.6916\n",
      "   % Time: 0:54:55.354984 | Iteration:  3200 | Batch:  532/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 0:56:39.002330 | Iteration:  3300 | Batch:  632/667 | Train loss: 0.6928 | Val loss: 0.6916\n",
      "\n",
      "=> EPOCH 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b480b7cd31a441880f2149243d77fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 0:58:21.822922 | Iteration:  3400 | Batch:   65/667 | Train loss: 0.6919 | Val loss: 0.6917\n",
      "   % Time: 1:00:04.773279 | Iteration:  3500 | Batch:  165/667 | Train loss: 0.6921 | Val loss: 0.6914\n",
      "   % Time: 1:01:47.408068 | Iteration:  3600 | Batch:  265/667 | Train loss: 0.6918 | Val loss: 0.6913\n",
      "   % Time: 1:03:30.645946 | Iteration:  3700 | Batch:  365/667 | Train loss: 0.6919 | Val loss: 0.6915\n",
      "   % Time: 1:05:14.800460 | Iteration:  3800 | Batch:  465/667 | Train loss: 0.6916 | Val loss: 0.6911\n",
      "   % Time: 1:06:58.463083 | Iteration:  3900 | Batch:  565/667 | Train loss: 0.6919 | Val loss: 0.6916\n",
      "   % Time: 1:08:41.594795 | Iteration:  4000 | Batch:  665/667 | Train loss: 0.6929 | Val loss: 0.6913\n",
      "\n",
      "=> EPOCH 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893e08e3e4bc4716b7054915fa0acfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:10:24.484646 | Iteration:  4100 | Batch:   98/667 | Train loss: 0.6921 | Val loss: 0.6913\n",
      "   % Time: 1:12:07.046520 | Iteration:  4200 | Batch:  198/667 | Train loss: 0.6919 | Val loss: 0.6914\n",
      "   % Time: 1:13:49.616556 | Iteration:  4300 | Batch:  298/667 | Train loss: 0.6917 | Val loss: 0.6912\n",
      "   % Time: 1:15:32.444589 | Iteration:  4400 | Batch:  398/667 | Train loss: 0.6913 | Val loss: 0.6908\n",
      "   % Time: 1:17:15.573810 | Iteration:  4500 | Batch:  498/667 | Train loss: 0.6914 | Val loss: 0.6909\n",
      "   % Time: 1:18:58.556091 | Iteration:  4600 | Batch:  598/667 | Train loss: 0.6912 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a788b04bd80d41d28bdd711d0b3bf7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:20:41.073296 | Iteration:  4700 | Batch:   31/667 | Train loss: 0.6920 | Val loss: 0.6909\n",
      "   % Time: 1:22:23.977725 | Iteration:  4800 | Batch:  131/667 | Train loss: 0.6911 | Val loss: 0.6912\n",
      "   % Time: 1:24:06.920420 | Iteration:  4900 | Batch:  231/667 | Train loss: 0.6903 | Val loss: 0.6909\n",
      "   % Time: 1:25:49.773948 | Iteration:  5000 | Batch:  331/667 | Train loss: 0.6910 | Val loss: 0.6914\n",
      "   % Time: 1:27:32.880611 | Iteration:  5100 | Batch:  431/667 | Train loss: 0.6911 | Val loss: 0.6917\n",
      "   % Time: 1:29:16.246776 | Iteration:  5200 | Batch:  531/667 | Train loss: 0.6906 | Val loss: 0.6913\n",
      "   % Time: 1:30:59.080945 | Iteration:  5300 | Batch:  631/667 | Train loss: 0.6915 | Val loss: 0.6915\n",
      "\n",
      "=> EPOCH 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478364f5fe384952a127c3ef0db17e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:32:41.803908 | Iteration:  5400 | Batch:   64/667 | Train loss: 0.6911 | Val loss: 0.6914\n",
      "=> Adjust learning rate to: 0.006999999999999999\n",
      "   % Time: 1:34:24.458104 | Iteration:  5500 | Batch:  164/667 | Train loss: 0.6895 | Val loss: 0.6916\n",
      "   % Time: 1:36:07.163432 | Iteration:  5600 | Batch:  264/667 | Train loss: 0.6908 | Val loss: 0.6913\n",
      "   % Time: 1:37:50.319805 | Iteration:  5700 | Batch:  364/667 | Train loss: 0.6914 | Val loss: 0.6912\n",
      "   % Time: 1:39:33.526270 | Iteration:  5800 | Batch:  464/667 | Train loss: 0.6895 | Val loss: 0.6910\n",
      "   % Time: 1:41:16.676685 | Iteration:  5900 | Batch:  564/667 | Train loss: 0.6906 | Val loss: 0.6911\n",
      "   % Time: 1:42:59.682476 | Iteration:  6000 | Batch:  664/667 | Train loss: 0.6901 | Val loss: 0.6910\n",
      "\n",
      "=> EPOCH 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bae6ee69d114834a5c8c7602c9ba8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time: 1:44:42.483787 | Iteration:  6100 | Batch:   97/667 | Train loss: 0.6890 | Val loss: 0.6912\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-77791d40d758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \"w+\")\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5416212a9406>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> EPOCH {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# total iteration within all batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5687f46f2bd9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOKENS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         x = tt.FloatTensor(self.df[self.config.TOKENS][idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/cathay/src/preprocessing/feature_engineering/bert_embedding.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, row_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                           \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                           \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                           \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                                          )\n\u001b[1;32m     33\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# however, we do not take cls & \\cls into consideration when building the embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mconvert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id_with_added_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/kll482/anaconda3/envs/cathay/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_tokens_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_token_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# saved = True\n",
    "# if 1 == 1:  # change to True to train\n",
    "#     iteration = n_total = train_loss = n_bad_loss = 0\n",
    "#     stop = False\n",
    "#     best_val_loss = float(\"inf\")\n",
    "#     init = datetime.now()\n",
    "#     config.epochs = 10\n",
    "# #     config.n_bad_loss 4\n",
    "#     if saved:\n",
    "#         write_log(\"Start record at {}\\n\".format(str(datetime.now())),\n",
    "#                   config.log_file,\n",
    "#                   \"w+\")\n",
    "#     for epoch in range(1, config.epochs+1):\n",
    "#         train(config, train_loader, val_loader, model, criterion, optimizer)\n",
    "#         if stop:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T07:27:10.966688Z",
     "start_time": "2020-08-05T07:27:10.964582Z"
    }
   },
   "source": [
    "## 8. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_name = config.best_model.split(\"/\")[-1][:-4] # default\n",
    "result_name = \"\"\n",
    "config.best_model = os.path.join(config.result_path, \"checkpoint/{}.pth\".format(result_name))\n",
    "config.log_file = os.path.join(config.log_path, \"{}.txt\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_load(config, \n",
    "                        BinGATConv(config.NUM_FEATURES, config.N_CLASSES).to(device),\n",
    "                        name=result_name,\n",
    "                       )\n",
    "y_true, y_pred, y_prob = test(config, test_loader, model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.10      0.18     21307\n",
      "         1.0       0.51      0.93      0.66     21336\n",
      "\n",
      "    accuracy                           0.52     42643\n",
      "   macro avg       0.56      0.52      0.42     42643\n",
      "weighted avg       0.56      0.52      0.42     42643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# write the report\n",
    "write_log(\"\\n{}\\n\\n{}\\n\".\\\n",
    "          format(\"=== Classification Report ===\",\n",
    "                 report\n",
    "                ),\n",
    "          config.log_file,\n",
    "          \"a+\")\n",
    "\n",
    "# print\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. Saving Testing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.PREDICTED_RESULT = os.path.join(\"result/graph/prediction\", \"{}.pkl\".format(result_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving predicted result\n",
    "with open(config.PREDICTED_RESULT, 'wb') as f:\n",
    "    pickle.dump([y_true, y_pred, y_prob], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.PREDICTED_RESULT, 'rb') as f:\n",
    "    y_true, y_pred, y_prob = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.log_file, \"r+\") as file:\n",
    "    logs = file.readlines()\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    for row in logs:\n",
    "        if len(row.split(\"|\")) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            train_loss.append(float(row.split(\"|\")[-2].strip().split(\" \")[-1]))\n",
    "            val_loss.append(float(row.split(\"|\")[-1].strip().split(\" \")[-1]))\n",
    "    assert len(train_loss) == len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(train_loss)), train_loss, '-b', label='train')\n",
    "ax.plot(range(len(val_loss)), val_loss, '--r', label='validation')\n",
    "leg = ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
